# 무하유 프로젝트 - 유해 콘텐츠 탐지 시스템

## 📋 프로젝트 개요

무하유 프로젝트는 이미지와 비디오에서 유해 콘텐츠를 탐지하는 AI 시스템입니다.
멀티모달 딥러닝 기술을 활용하여 다양한 유해 요소를 자동으로 탐지합니다.

## 🎯 연구 목표

### 핵심 과제
1. **유해 콘텐츠 정의**
2. **이미지/동영상 내 유해 콘텐츠 방법론(모델) 조사** (논문 조사 및 파일럿 테스트)
3. **벤치마크 데이터가 아닌 실제 data 수집**
   - 혐오 표현 포함 이미지/동영상 데이터 각 100개 이상
   - 구글 드라이브 업로드
4. **공개 데이터셋 조사 및 수집** (구글 드라이브 업로드)
5. **유해 콘텐츠 탐지 모델 개발**
   - 멀티모달 모델 활용
   - 벤치마크 데이터 기준 정확도 0.75 이상

### 도전 과제
1. 벤치마크 데이터 기준 정확도 0.80 이상
2. 모델 경량화
3. 설명가능한 모델

## 🔍 유해 콘텐츠 정의

### 1. 객체 기반 유해 콘텐츠 (필수)
- **목적**: 쉽게 탐지 가능, 실시간 분석 가능
- **대상 예시**: 칼, 총, 가위, 병
- **설명**: COCO/Open Images 등 공개 데이터셋 클래스와 겹쳐 YOLO pretrained 모델 활용 가능

### 2. 행동/상호작용 기반 유해 콘텐츠 (선택/도전 과제→필수)
- **목적**: 단순 객체 탐지를 넘어 유해 행위 판단
- **대상 예시**: 사람과 객체 상호작용 → 총/칼 들고 공격, 폭력 장면 등
- **설명**: HOI/행동 인식 모델 사용, 실시간성 떨어짐

> **포괄적 검출**: 무기, 음주, 흡연, 폭력, 음란 등 다양한 유형을 포함하여 검출

## 🏗️ 프로젝트 구조

```
무하유/
├── 무하유_유해콘텐츠_데이터/        # 공통 데이터셋
│   ├── README.md                     # 데이터셋 설명 및 사용 가이드
│   ├── 1_공개_데이터셋/              # 공개 데이터셋 (수동 다운로드)
│   │   ├── HOD_Dataset/              # 유해 이미지 10,631개
│   │   ├── RWF-2000/                # 폭력 비디오 2,000개
│   │   ├── RLVS/                    # 실생활 폭력 비디오 2,000개
│   │   └── COCO_Safe_Dataset/       # 안전 이미지 5,000개
│   ├── 2_실제_수집_데이터/          # 팀원별 수집 데이터
│   │   ├── 이미지/                   # 유해 이미지
│   │   ├── 비디오/                  # 유해 비디오
│   │   ├── 안전_이미지/             # 안전 이미지
│   │   └── 안전_비디오/             # 안전 비디오
│   └── 3_라벨링_파일/               # 자동 생성 라벨링 정보
│
│
├── 박상원/                           # 팀원 1 작업 폴더
│   ├── experiments/                  # 개인 실험 기록
│   ├── final_model_v1/             # 초기 모델
│   ├── final_model_v2/             # 개선 모델
│   └── final_model_v3/             # 추가 개선 모델
│
├── 임영재/                           # 팀원 2 작업 폴더
│   ├── experiments/
│   ├── final_model_v1/
│   └── ...
│
├── 안지산/                           # 팀원 3 작업 폴더
│   ├── experiments/
│   ├── final_model_v1/
│   └── ...
│
└── final/                            # 최종 통합 모델
    ├── final_model.py               # 최종 stable 모델 코드
    ├── image_model_best.pth        # 최종 이미지 모델
    ├── video_model_best.pth        # 최종 비디오 모델
    ├── image_confusion_matrix.png   # 이미지 성능 평가
    ├── video_confusion_matrix.png   # 비디오 성능 평가
    └── train_log.txt                # 학습 기록
```

## 📊 데이터셋 구성

### 공개 데이터셋
각 데이터셋을 다운로드하여 `무하유_유해콘텐츠_데이터/1_공개_데이터셋/` 폴더에 배치:
- **HOD Dataset**: 유해 이미지 10,631개
- **RWF-2000**: 폭력/비폭력 비디오 2,000개
- **RLVS**: 실생활 폭력 비디오 2,000개
- **COCO Safe**: 안전 이미지 5,000개

상세한 다운로드 링크 및 안내는 `무하유_유해콘텐츠_데이터/1_공개_데이터셋/` 폴더의 README를 참고하세요.

### 실제 수집 데이터
각 팀원이 개별적으로 수집 및 라벨링 (팀원별 200개):
- 유해 이미지: 100개
- 유해 비디오: 100개

> 라벨링 도구는 `박상원/팀원_라벨링/` 폴더에 있습니다.

## 🔬 연구 진행 방식

### 초반
- 각 팀원이 **객체 기반 유해 콘텐츠 탐지** 관련 논문 검토
- 이미지/영상 모델 후보 조사 및 구조 비교
- **파일럿 테스트** 진행: 작은 샘플 데이터로 모델 성능 확인

### 중반
- 각자 **데이터 수집** (200개 이미지/영상) 진행
- 매주 **중간 공유 및 피드백 세션**
  - 모델 구조, 데이터셋, 성능 비교
  - 개선 사항 논의 및 적용

### 후반
- 세 명이 수집한 **총 600개 데이터 + 공개 데이터셋** 통합
- 각자의 모델을 **통합 평가**
- 성능 기준으로 **최종 모델 선정**
- 최종 보고서 작성 및 발표 자료 준비

## 📈 성능 목표

- **벤치마크 데이터 기준 정확도**: 0.75 이상 (필수)
- **벤치마크 데이터 기준 정확도**: 0.80 이상 (도전)
- **모델 경량화** (도전)
- **설명가능한 모델** (도전)

## 🚀 시작하기

### 1. 공개 데이터셋 다운로드
`무하유_유해콘텐츠_데이터/1_공개_데이터셋/` 폴더의 README를 참고하여 공개 데이터셋을 다운로드하고 배치합니다.

### 2. 데이터 수집 및 라벨링
각 팀원은 `무하유_유해콘텐츠_데이터/3_라벨링_파일/개인/` 폴더의 가이드를 참고하여 자신의 데이터를 수집하고 라벨링합니다.

> 라벨링 도구: `박상원/팀원_라벨링/` 폴더의 `team_labeling_tool.py`와 가이드를 참고하세요.

### 3. 모델 학습
각자 `[자신의_이름]/` 폴더에서 모델을 실험하고 개선합니다.

### 4. 최종 통합
모든 팀원의 실험 결과를 통합하여 최종 모델을 결정합니다.

## ⚠️ 주의사항

1. **용량 문제**: 공개 데이터셋은 GitHub에 업로드하지 않음 (각자 다운로드)
2. **라벨링 의무**: 각 팀원은 최소 200개 데이터 수집 및 검증 필수

## 👥 팀원

- **박상원**
- **임영재**
- **안지산**

## 📧 문의

프로젝트 관련 문의사항은 GitHub Issues를 이용해주세요.

