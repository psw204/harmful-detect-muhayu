# 무하유 프로젝트 - 유해 콘텐츠 탐지 시스템

## 📋 프로젝트 개요

무하유 프로젝트는 이미지와 비디오에서 유해 콘텐츠를 탐지하는 AI 시스템입니다.
멀티모달 딥러닝 기술을 활용하여 다양한 유해 요소를 자동으로 탐지합니다.

## 🎯 연구 목표

### 핵심 과제
1. **유해 콘텐츠 정의**
2. **이미지/동영상 내 유해 콘텐츠 방법론(모델) 조사** (논문 조사 및 파일럿 테스트)
3. **벤치마크 데이터가 아닌 실제 data 수집**
   - 혐오 표현 포함 이미지/동영상 데이터 각 100개 이상
   - 구글 드라이브 업로드
4. **공개 데이터셋 조사 및 수집** (구글 드라이브 업로드)
5. **유해 콘텐츠 탐지 모델 개발**
   - 멀티모달 모델 활용
   - 벤치마크 데이터 기준 정확도 0.75 이상

### 도전 과제
1. 벤치마크 데이터 기준 정확도 0.80 이상
2. 모델 경량화
3. 설명가능한 모델

## 🔍 유해 콘텐츠 정의

### 1. 객체 기반 유해 콘텐츠 (필수)
- **목적**: 쉽게 탐지 가능, 실시간 분석 가능
- **대상 예시**: 칼, 총, 가위, 병
- **설명**: COCO/Open Images 등 공개 데이터셋 클래스와 겹쳐 YOLO pretrained 모델 활용 가능

### 2. 행동/상호작용 기반 유해 콘텐츠 (선택/도전 과제→필수)
- **목적**: 단순 객체 탐지를 넘어 유해 행위 판단
- **대상 예시**: 사람과 객체 상호작용 → 총/칼 들고 공격, 폭력 장면 등
- **설명**: HOI/행동 인식 모델 사용, 실시간성 떨어짐

> **포괄적 검출**: 무기, 음주, 흡연, 폭력, 음란 등 다양한 유형을 포함하여 검출

## 🏗️ 프로젝트 구조

```
무하유/
├── 무하유_유해콘텐츠_데이터/        # 공통 데이터셋 (학습용)
│   ├── README.md                     # 데이터셋 설명 및 사용 가이드
│   ├── 1_공개_데이터셋/              # 공개 데이터셋 (수동 다운로드)
│   │   ├── HOD_Dataset/              # 유해 이미지 10,631개
│   │   ├── RWF-2000/                # 폭력 비디오 2,000개
│   │   ├── RLVS/                    # 실생활 폭력 비디오 2,000개
│   │   └── COCO_Safe_Dataset/       # 안전 이미지 5,000개
│   ├── 2_실제_수집_데이터/          # 팀원별 수집 데이터 (학습용)
│   │   ├── 이미지/                   # 유해 이미지
│   │   ├── 비디오/                  # 유해 비디오
│   │   ├── 안전_이미지/             # 안전 이미지
│   │   └── 안전_비디오/             # 안전 비디오
│   └── 3_라벨링_파일/               # 자동 생성 라벨링 정보
│
├── 무하유_유해콘텐츠_데이터_모델선정/  # 최종 평가용 데이터
│   ├── 2_실제_수집_데이터/          # 팀원별 수집 데이터 (평가용)
│   │   ├── 박상원/                   # 인당 400개
│   │   │   ├── 이미지/               # 유해 이미지 100개
│   │   │   ├── 안전_이미지/         # 안전 이미지 100개
│   │   │   ├── 비디오/              # 유해 비디오 100개
│   │   │   └── 안전_비디오/         # 안전 비디오 100개
│   │   ├── 안지산/ (동일)
│   │   └── 임영재/ (동일)
│   └── 3_라벨링_파일/               # 카테고리별 라벨링 결과
│       ├── 박상원/
│       │   └── 박상원_labels_categorized.json
│       ├── 안지산/
│       └── 임영재/
│
├── 박상원/                           # 팀원 1 작업 폴더
│   ├── experiments/                  # 개인 실험 기록
│   ├── final_model_v1/             # 초기 모델
│   ├── final_model_v2/             # 개선 모델
│   ├── final_model_v3/             # 추가 개선 모델
│   ├── 팀원_라벨링/                 # 초기 라벨링 도구
│   └── 팀원_라벨링_모델선정/        # 카테고리별 라벨링 도구 v2.0
│       ├── team_labeling_tool_with_category.py
│       ├── 팀원_라벨링_가이드_카테고리버전.md
│       └── README.md
│
├── 임영재/                           # 팀원 2 작업 폴더
│   ├── experiments/
│   ├── final_model_v1/
│   └── ...
│
├── 안지산/                           # 팀원 3 작업 폴더
│   ├── experiments/
│   ├── final_model_v1/
│   └── ...
│
└── final/                            # 최종 통합 모델
    ├── final_model.py               # 최종 stable 모델 코드
    ├── image_model_best.pth        # 최종 이미지 모델
    ├── video_model_best.pth        # 최종 비디오 모델
    ├── image_confusion_matrix.png   # 이미지 성능 평가
    ├── video_confusion_matrix.png   # 비디오 성능 평가
    └── train_log.txt                # 학습 기록
```

## 📊 데이터셋 구성

### 공개 데이터셋
각 데이터셋을 다운로드하여 `무하유_유해콘텐츠_데이터/1_공개_데이터셋/` 폴더에 배치:
- **HOD Dataset**: 유해 이미지 10,631개
- **RWF-2000**: 폭력/비폭력 비디오 2,000개
- **RLVS**: 실생활 폭력 비디오 2,000개
- **COCO Safe**: 안전 이미지 5,000개

상세한 다운로드 링크 및 안내는 `무하유_유해콘텐츠_데이터/1_공개_데이터셋/` 폴더의 README를 참고하세요.

### 실제 수집 데이터

#### 학습용 데이터 (초기 수집)
각 팀원이 개별적으로 수집 및 라벨링 (팀원별 400개):
- 안전 이미지: 100개
- 유해 이미지: 100개
- 안전 비디오: 100개
- 유해 비디오: 100개

> 초기 라벨링 도구는 `박상원/팀원_라벨링/` 폴더에 있습니다.

#### 최종 평가용 데이터 (독립 평가)
각 팀원이 개별적으로 수집 및 카테고리별 라벨링 (팀원별 400개, 총 1200개):
- 안전 이미지: 100개
- 유해 이미지: 100개
- 안전 비디오: 100개
- 유해 비디오: 100개

**10개 카테고리**: weapons, violence, alcohol, smoking, drugs, blood, threat, sexual, dangerous, safe

> **⚠️ 중요**: 이 1200개 데이터는 오직 최종 평가용입니다. 학습에 사용 금지!
> 
> 카테고리별 라벨링 도구 v2.0은 `박상원/팀원_라벨링_모델선정/` 폴더에 있습니다.

## 🔬 연구 진행 방식

### 초반
- 각 팀원이 **객체 기반 유해 콘텐츠 탐지** 관련 논문 검토
- 이미지/영상 모델 후보 조사 및 구조 비교
- **파일럿 테스트** 진행: 작은 샘플 데이터로 모델 성능 확인

### 중반
- 각자 **데이터 수집** (400개 이미지/영상) 진행
- 매주 **중간 공유 및 피드백 세션**
  - 모델 구조, 데이터셋, 성능 비교
  - 개선 사항 논의 및 적용

### 후반
- 각자의 모델을 **통합 평가**
- **최종 독립 평가**: 1200개 데이터(400개 × 3명)로만 카테고리별 성능 분석
  - 공개 데이터셋은 최종 평가에 포함하지 않음
  - 순수하게 팀원이 수집한 1200개 데이터만으로 평가
- 성능 기준으로 **최종 모델 선정**
- 최종 보고서 작성 및 발표 자료 준비

## 📈 성능 목표

- **벤치마크 데이터 기준 정확도**: 0.75 이상 (필수)
- **벤치마크 데이터 기준 정확도**: 0.80 이상 (도전)
- **모델 경량화** (도전)
- **설명가능한 모델** (도전)

## 🚀 시작하기

### 1. 공개 데이터셋 다운로드
`무하유_유해콘텐츠_데이터/1_공개_데이터셋/` 폴더의 README를 참고하여 공개 데이터셋을 다운로드하고 배치합니다.

### 2. 데이터 수집 및 라벨링

#### 학습용 데이터 라벨링
각 팀원은 `무하유_유해콘텐츠_데이터/3_라벨링_파일/개인/` 폴더의 가이드를 참고하여 자신의 데이터를 수집하고 라벨링합니다.

> 초기 라벨링 도구: `박상원/팀원_라벨링/` 폴더의 `team_labeling_tool.py`와 가이드를 참고하세요.

#### 최종 평가용 데이터 라벨링 (카테고리별)
각 팀원은 `무하유_유해콘텐츠_데이터_모델선정/2_실제_수집_데이터/` 폴더에 자신의 데이터를 배치하고 카테고리별로 라벨링합니다.

> **카테고리별 라벨링 도구 v2.0**: `박상원/팀원_라벨링_모델선정/` 폴더의 `team_labeling_tool_with_category.py`와 가이드를 참고하세요.
> 
> - 10개 카테고리 세분화 (weapons, violence, alcohol, smoking, drugs, blood, threat, sexual, dangerous, safe)
> - 파일 해시 기반 중복 검출
> - 완전 수동 라벨링 (YOLO 없음)

### 3. 모델 학습
각자 `[자신의_이름]/` 폴더에서 모델을 실험하고 개선합니다.

### 4. 최종 평가
- 각 팀원의 모델을 **1200개 독립 평가 데이터**로만 평가
  - 공개 데이터셋은 최종 평가에 포함하지 않음
  - 순수하게 팀원이 수집한 1200개 데이터만으로 평가
- 카테고리별 성능 분석 (어떤 유형에서 성능이 떨어지는지 확인)
- 성능 기준으로 **최종 모델 선정**

> **⚠️ 독립 평가 주의**: 각자가 수집한 400개 데이터는 자신의 모델 학습에 사용하지 않습니다!

## ⚠️ 주의사항

1. **용량 문제**: 공개 데이터셋은 GitHub에 업로드하지 않음 (각자 다운로드)
2. **라벨링 의무**: 각 팀원은 최소 400개 데이터 수집 및 검증 필수 (학습용)
3. **최종 평가 데이터**: 각 팀원은 400개 데이터를 카테고리별로 라벨링 필수 (총 1200개, 독립 평가용)
4. **독립 평가**: 최종 평가용 1200개 데이터는 학습에 사용하지 않음
5. **폴더 이름 ≠ 최종 라벨**: 카테고리별 라벨링 시 폴더 이름이 아닌 실제 내용을 기준으로 판단

## 👥 팀원

- **박상원**
- **임영재**
- **안지산**

## 📧 문의

프로젝트 관련 문의사항은 GitHub Issues를 이용해주세요.

> **작성자**: 박상원  
> **작성일**: 2025년 2학기