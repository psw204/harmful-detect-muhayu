# 무하유 유해 콘텐츠 탐지 모델 개발 보고서 4
**Final Model 4 - 클래스 불균형 해결 및 학습 안정화**

> **작성자**: 박상원  
> **작성일**: 2025년 2학기

---

## 1. Final Model 3의 문제점 복기

### 핵심 문제
1.  **Epoch 간 최적 Threshold 변동**: 0.7 → 0.35로 변화 (모델 불안정)
2.  **수동 Threshold 선택**: 매 epoch마다 최적값을 수동으로 확인
3.  **클래스 불균형**: 유해:안전 = 2.68:1 (비디오), 4.15:1 (이미지)
4.  **배치 크기 작음**: VIDEO_BATCH_SIZE = 2 (학습 불안정 원인)
5.  Threshold 분석으로 F1 0.9405 달성

### 원인 분석
- **클래스 불균형**: 손실 함수가 다수 클래스(유해)에 편향
- **작은 배치**: 2개 샘플로는 BatchNorm이 불안정
- **Sigmoid 중복**: BCELoss 사용 시 Sigmoid 중복 적용 → 수치 불안정

---

## 2. Final Model 4 개선 사항

### 2.1 클래스 불균형 처리 (pos_weight 적용)

#### 클래스 불균형 계산
```python
# 학습 데이터의 클래스 분포 분석
num_harmful = sum(train_labels)  # 유해 샘플 수: 2,393
num_safe = len(train_labels) - num_harmful  # 안전 샘플 수: 893
pos_weight = torch.tensor([num_safe / num_harmful]).to(DEVICE)
print(f"\n✓ pos_weight={pos_weight.item():.4f}")
print(f"  (안전: {num_safe}개, 유해: {num_harmful}개)")

# 결과: pos_weight = 0.3732
# 의미: 유해 샘플 손실에 0.3732 가중치 적용 (안전 샘플을 더 중요하게)
```

#### BCEWithLogitsLoss로 변경
```python
# 기존 (Final Model 3)
criterion = nn.BCELoss()  # pos_weight 지원 안 함

# 개선 (Final Model 4)
criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
```

**pos_weight의 의미**:
- 안전 샘플이 적으므로 안전 샘플의 손실에 높은 가중치
- `pos_weight = num_safe / num_harmful = 893 / 2393 = 0.3732`
- 유해 샘플을 0.3732배 가중 (안전 샘플은 1.0배)
- **효과**: 모델이 안전 샘플도 제대로 학습하도록 유도

### 2.2 VideoHarmfulClassifier Sigmoid 제거

#### 변경 전 (Final Model 3)
```python
self.classifier = nn.Sequential(
    nn.Linear(input_dim, 256),
    nn.ReLU(),
    nn.BatchNorm1d(256),
    nn.Dropout(0.5),
    nn.Linear(256, 128),
    nn.ReLU(),
    nn.BatchNorm1d(128),
    nn.Dropout(0.4),
    nn.Linear(128, 1),
    nn.Sigmoid()  # ← BCEWithLogitsLoss와 중복!
)
```

#### 변경 후 (Final Model 4)
```python
self.classifier = nn.Sequential(
    nn.Linear(input_dim, 256),
    nn.ReLU(),
    nn.BatchNorm1d(256),
    nn.Dropout(0.5),
    nn.Linear(256, 128),
    nn.ReLU(),
    nn.BatchNorm1d(128),
    nn.Dropout(0.4),
    nn.Linear(128, 1)  # Sigmoid 제거!
)

def forward(self, x):
    transformed = self.transformer(x)
    pooled = transformed.mean(dim=1)
    return self.classifier(pooled)  # 로짓 반환 (Sigmoid 전)
```

**개선 효과**:
- **수치 안정성 향상**: BCEWithLogitsLoss가 내부적으로 log-sum-exp trick 사용
- **중복 계산 제거**: Sigmoid를 한 번만 계산
- **그래디언트 흐름 개선**: 로짓 공간에서 직접 계산

#### 검증 시 Sigmoid 적용
```python
# 학습 시: 로짓 반환 (BCEWithLogitsLoss가 처리)
outputs = model(features).squeeze()
loss = criterion(outputs, labels_batch)

# 검증 시: 확률로 변환
outputs = model(features).squeeze()
outputs = torch.sigmoid(outputs)  # ← 명시적 Sigmoid
```

### 2.3 자동 Threshold 선택 로직

#### 변경 전 (Final Model 3)
```python
# 수동 선택
opt_th = 0.4  # 수동으로 지정
val_preds = (val_outputs_np > opt_th).astype(int)
```

#### 변경 후 (Final Model 4)
```python
# 자동 선택
best_th = 0.5
best_th_f1 = 0
print(f"\n[Threshold 분석 @ Epoch {epoch+1}]")

# 더 세밀한 범위에서 탐색
for th in [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]:
    preds = (val_outputs_np > th).astype(int)
    precision, recall, f1, _ = precision_recall_fscore_support(
        val_true_np, preds, average='binary', zero_division=0)
    print(f"  Threshold={th:.2f}: Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}")
    
    # 최고 F1 자동 선택
    if f1 > best_th_f1:
        best_th_f1 = f1
        best_th = th

# 자동 선택된 최적 threshold 사용
val_preds = (val_outputs_np > best_th).astype(int)
```

**개선 효과**:
- 매 epoch 자동으로 최적 threshold 찾기
- 수동 개입 불필요
- 재현 가능성 보장

### 2.4 Best Threshold 저장

```python
# 기존 (Final Model 3)
torch.save(model.state_dict(), 'video_model_best.pth')

# 개선 (Final Model 4)
torch.save({
    'model_state_dict': model.state_dict(),
    'best_threshold': best_th  # 최적 threshold도 함께 저장
}, 'video_model_best.pth')
```

**활용**:
- 추론 시 저장된 최적 threshold 사용
- 학습 환경과 동일한 threshold 보장

### 2.5 비디오 학습 설정 최적화

```python
# 배치 크기 증가 (Final Model 3: 2 → Final Model 4: 4)
VIDEO_BATCH_SIZE = 4  # 메모리 효율성 개선으로 가능

# 학습률 감소 (Final Model 3: 0.0005 → Final Model 4: 0.0003)
VIDEO_LR = 0.0003  # 더 안정적인 학습
```

**이유**:
- **배치 증가**: BatchNorm 안정화, 학습 속도 향상
- **학습률 감소**: 세밀한 최적화, 과적합 방지

### 2.6 Confusion Matrix에 Threshold 표시

```python
# Confusion Matrix 제목에 threshold 포함
plt.title(f'Video Model Confusion Matrix (F1={best_f1:.3f}, Th={best_threshold:.2f})')
```

---

## 3. 실행 결과

### 3.1 클래스 불균형 보정 효과

```
✓ pos_weight=0.3732
  (안전: 893개, 유해: 2,393개)
```

### 3.2 Threshold 분석 결과

#### Epoch 1
```
[Threshold 분석 @ Epoch 1]
  Threshold=0.30: Precision=0.8482, Recall=0.9905, F1=0.9138
  Threshold=0.35: Precision=0.8639, Recall=0.9905, F1=0.9229
  Threshold=0.40: Precision=0.8708, Recall=0.9882, F1=0.9258
  Threshold=0.45: Precision=0.8742, Recall=0.9858, F1=0.9267
  Threshold=0.50: Precision=0.8797, Recall=0.9858, F1=0.9298
  Threshold=0.55: Precision=0.8854, Recall=0.9858, F1=0.9329
  Threshold=0.60: Precision=0.8963, Recall=0.9811, F1=0.9368
  Threshold=0.65: Precision=0.9037, Recall=0.9764, F1=0.9386
  Threshold=0.70: Precision=0.9113, Recall=0.9716, F1=0.9405 ← 자동 선택!
```

**결과**: 
- 최적 Threshold: **0.70** (자동 선택)
- F1: **0.9405**
- Precision: 0.9113, Recall: 0.9716

#### Epoch 2
```
[Threshold 분석 @ Epoch 2]
  Threshold=0.30: Precision=0.8072, Recall=0.9598, F1=0.8769
  Threshold=0.35: Precision=0.8072, Recall=0.9598, F1=0.8769
  Threshold=0.40: Precision=0.8088, Recall=0.9598, F1=0.8778
  Threshold=0.45: Precision=0.8088, Recall=0.9598, F1=0.8778
  Threshold=0.50: Precision=0.8088, Recall=0.9598, F1=0.8778
  Threshold=0.55: Precision=0.8088, Recall=0.9598, F1=0.8778
  Threshold=0.60: Precision=0.8120, Recall=0.9598, F1=0.8797
  Threshold=0.65: Precision=0.8165, Recall=0.9574, F1=0.8814
  Threshold=0.70: Precision=0.8262, Recall=0.9551, F1=0.8860 ← 자동 선택!
```

**결과**:
- 최적 Threshold: **0.70** (일관성 유지)
- F1: 0.8860 (Epoch 1 대비 하락)

#### Epoch 3
```
[Threshold 분석 @ Epoch 3]
  Threshold=0.30: Precision=0.9116, Recall=0.9504, F1=0.9306
  Threshold=0.35: Precision=0.9485, Recall=0.9149, F1=0.9314 ← 자동 선택!
  Threshold=0.40: Precision=0.9704, Recall=0.8534, F1=0.9082
  Threshold=0.45: Precision=0.9849, Recall=0.7707, F1=0.8647
  Threshold=0.50: Precision=0.9930, Recall=0.6738, F1=0.8028
```

**결과**:
- 최적 Threshold: **0.35** (변화!)
- F1: **0.9314**
- Precision: 0.9485, Recall: 0.9149
- **분석**: 모델이 보수적으로 변함 (Recall 감소, Precision 증가)

#### Epoch 4~6
| Epoch | 최적 Th | Loss | Precision | Recall | F1-Score |
|-------|---------|------|-----------|--------|----------|
| 4 | 0.40 | 0.2362 | 0.9650 | 0.9125 | **0.9380** |
| 5 | 0.40 | 0.2174 | 0.9581 | 0.9740 | **0.9660** |
| 6 | 0.45 | 0.2091 | 0.9673 | 0.9740 | **0.9706** ← 최고! |

### 3.3 최종 비디오 모델 성능

| Metric | Best (Epoch 6) | 비고 |
|--------|---------------|------|
| F1-Score | **0.9706** |  목표 초과 달성! |
| Precision | 0.9673 | 매우 높은 정밀도 |
| Recall | 0.9740 | 높은 재현율 유지 |
| Threshold | 0.45 | 최적 임계값 |
| Loss | 0.2091 | 안정적 감소 |

**결과**:  **Best F1 = 0.9706** (Epoch 6, Threshold 0.45)
- Final Model 3 대비 **+0.0301 향상** (0.9405 → 0.9706)
- **목표 0.75 대폭 초과!** (0.9706 / 0.75 = 129%)
- Precision과 Recall 모두 0.97 이상
- **매우 균형잡힌 성능**

### 3.4 이미지 모델 성능

**결과**:  일관되게 우수 (F1 0.99+)
- pos_weight 효과는 주로 비디오에 적용
- 이미지는 이미 안정적

---

## 4. 개선 효과 분석

### 4.1 pos_weight 효과

| Epoch | Model 3 (no pos_weight) | Model 4 (pos_weight) | 개선 |
|-------|------------------------|---------------------|------|
| 1 | F1 0.9405 | F1 0.9405 | 동일 |
| 6 | - | **F1 0.9706** | 최종 +0.0301 |

**인사이트**:
- 초반에는 큰 차이 없음
- 후반으로 갈수록 효과 증가 (안정적 학습)
- Loss 감소 패턴 안정화

### 4.2 자동 Threshold 선택 효과

```
Epoch 1: Th 0.70 (High Precision)
Epoch 2: Th 0.70 (일관성)
Epoch 3: Th 0.35 (모델 변화 적응)
Epoch 4: Th 0.40 (균형)
Epoch 5: Th 0.40 (일관성)
Epoch 6: Th 0.45 (최적 균형)
```

**인사이트**:
- 모델 학습에 따라 최적 threshold 자동 추적
- 수동 선택 불필요
- 재현 가능성 보장

### 4.3 배치 크기 증가 효과 (2 → 4)

- 학습 속도 약간 증가 (53분 → 53-55분 비슷)
- BatchNorm 안정성 향상
- 메모리 사용량 증가 (관리 필요)

### 4.4 BCEWithLogitsLoss 효과

- 수치 안정성 향상 (그래디언트 소실/폭발 방지)
- 학습 초반 Loss 감소 속도 향상
- Sigmoid 중복 제거

---

## 5. 문제점 및 한계

### 5.1 일부 비디오 손상
```
[h264 @ ...] mb_type 104 in P slice too large at 98 31
[h264 @ ...] error while decoding MB 98 31
```
- 일부 비디오 디코딩 오류
- 학습에 영향은 없으나 로그 지저분
- **개선 필요**: 사전 검증 및 필터링

### 5.2 Threshold 변동 여전히 존재
- Epoch 1-2: 0.70
- Epoch 3-5: 0.35-0.40
- Epoch 6: 0.45
- **분석**: 모델이 학습하면서 확률 분포가 변함
- **정상적 현상**: 최종 모델의 threshold (0.45) 사용하면 됨

### 5.3 메모리 사용량 증가
- 배치 크기 4로 증가 → GPU 메모리 더 많이 사용
- **한계**: 더 큰 배치 크기는 메모리 부족 위험

---

## 6. 개선 계획 (→ Final Model 5)

### 6.1 GPU 메모리 최적화
```python
# CLIP과 SlowFast 특징을 CPU로 즉시 이동
clip_features = self.clip_model.encode_image(clip_image).squeeze()
clip_features = clip_features.cpu()  # ← 즉시 CPU로

slowfast_feat = self.slowfast([slow_pathway, fast_pathway])
slowfast_feat = slowfast_feat.squeeze().cpu()  # ← 즉시 CPU로
```

**기대 효과**:
- GPU 메모리 절약
- 배치 크기 추가 증가 가능 (4 → 8?)

### 6.2 비디오 검증 함수 추가
```python
def validate_video(video_path):
    """손상된 비디오 사전 필터링"""
    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return False
        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if total == 0:
            return False
        # 몇 개 프레임 샘플링해서 읽기 테스트
        for idx in [0, total//2, total-1]:
            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
            ret, frame = cap.read()
            if not ret:
                return False
        cap.release()
        return True
    except:
        return False

# 데이터 준비 시 적용
vpaths_filtered = [vp for vp in vpaths if validate_video(vp)]
```

### 6.3 Transformer nhead 동적 설정
```python
# 현재: nhead=2 고정
# 문제: input_dim이 2로 나누어떨어지지 않으면 오류

# 개선: input_dim에 맞게 동적 설정
def find_best_nhead(input_dim, max_heads=16):
    """input_dim을 나눌 수 있는 최대 head 수 찾기"""
    for nhead in range(min(max_heads, input_dim), 0, -1):
        if input_dim % nhead == 0:
            return nhead
    return 1

nhead = find_best_nhead(input_dim)
encoder_layer = nn.TransformerEncoderLayer(
    d_model=input_dim,
    nhead=nhead,  # 동적 설정
    ...
)
```

---

## 7. 결론

### 성과
 **클래스 불균형 해결**: pos_weight 적용으로 안정적 학습
 **비디오 F1 역대 최고**: **0.9706** (Epoch 6)
 **자동 Threshold 선택**: 수동 개입 불필요
 **BCEWithLogitsLoss**: 수치 안정성 향상
 **배치 크기 증가**: 2 → 4 (학습 안정화)
 **Best Threshold 저장**: 추론 시 활용 가능

### 개선 효과 요약
| 항목 | Model 3 | Model 4 | 개선 |
|------|---------|---------|------|
| 비디오 F1 | 0.9405 | **0.9706** | **+0.0301** |
| Precision | 0.9113 | **0.9673** | **+0.0560** |
| Recall | 0.9716 | 0.9740 | +0.0024 |
| Threshold | 수동 | **자동 선택** | 개선 |
| 배치 크기 | 2 | **4** | **x2** |
| pos_weight |  | ** 0.3732** | 추가 |

### 핵심 인사이트
 **클래스 불균형 보정의 중요성**
- pos_weight 적용으로 학습 안정화 및 성능 향상
- 안전 샘플에 대한 학습 개선

 **자동 Threshold 선택의 효율성**
- 매 epoch마다 최적 threshold 자동 추적
- 모델 학습 단계에 따라 적응적으로 변화

 **수치 안정성의 중요성**
- BCEWithLogitsLoss로 Sigmoid 중복 제거
- 그래디언트 흐름 개선

### 남은 과제
 GPU 메모리 효율성 (배치 크기 추가 증가 위해)
 손상된 비디오 필터링
 Transformer nhead 동적 설정

### 다음 단계
Final Model 5에서는 GPU 메모리를 최적화하여 CLIP과 SlowFast 특징을 즉시 CPU로 이동시키고, 손상된 비디오를 사전 필터링하는 검증 함수를 추가하며, Transformer의 nhead를 input_dim에 맞게 동적으로 설정하여 더 유연한 모델 구조를 만들 예정입니다.

