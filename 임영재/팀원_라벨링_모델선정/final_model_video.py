#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
os.environ["TRANSFORMERS_NO_TF"] = "1"

import sys
import json
import subprocess
from collections import Counter
from glob import glob

# ğŸ”§ numpy 2.x í˜¸í™˜ íŒ¨ì¹˜ (typeDict â†’ sctypeDict)
import numpy as np
if not hasattr(np, "typeDict") and hasattr(np, "sctypeDict"):
    np.typeDict = np.sctypeDict

import torch
import numpy as np  # ìœ„ì—ì„œ ì´ë¯¸ ì„í¬íŠ¸í–ˆì§€ë§Œ, ìˆì–´ë„ ìƒê´€ ì—†ìŒ
from tqdm import tqdm
import torchvision.transforms as T

VIDEO_EXTS = (".mp4", ".avi", ".mov", ".mkv")

def get_all_videos(root):
    """
    root ì•„ë˜ ëª¨ë“  í•˜ìœ„ í´ë”ê¹Œì§€ ë’¤ì ¸ì„œ ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œë¥¼
    root ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ(relative path) ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.
      ì˜ˆ) category1/clip_001.mp4
    """
    rel_paths = []
    for dirpath, _, filenames in os.walk(root):
        for f in filenames:
            if f.lower().endswith(VIDEO_EXTS):
                full = os.path.join(dirpath, f)
                rel = os.path.relpath(full, root)  # root ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ
                rel_paths.append(rel)
    return sorted(rel_paths)


# --------------------------------
# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
# --------------------------------
ROOT_BASE = "/home/jovyan/kau-muhayu-multimodal-harmful-content-detect"

# ì‚¬ëŒë³„ ì›ë³¸ ë¹„ë””ì˜¤ê°€ ìˆëŠ” ê³³
SRC_ROOT = os.path.join(
    ROOT_BASE,
    "ë¬´í•˜ìœ _ìœ í•´ì½˜í…ì¸ _ë°ì´í„°_ëª¨ë¸ì„ ì •",
    "2_ì‹¤ì œ_ìˆ˜ì§‘_ë°ì´í„°"
)

# ê²°ê³¼ / í”„ë ˆì„ ì €ì¥ ë£¨íŠ¸
OUT_ROOT = os.path.join(
    ROOT_BASE,
    "ì„ì˜ì¬",
    "íŒ€ì›_ë¼ë²¨ë§_ëª¨ë¸ì„ ì •",
    "ê²°ê³¼_ë°ì´í„°_32"
)

CATEG_ROOT = os.path.join(
    ROOT_BASE,
    "ì„ì˜ì¬",
    "íŒ€ì›_ë¼ë²¨ë§_ëª¨ë¸ì„ ì •",
    "íŒ€ì›_ë¼ë²¨ë§"
)

# ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ
SCRIPT_DIR = os.path.join(ROOT_BASE, "ì„ì˜ì¬", "scripts")
sys.path.append(SCRIPT_DIR)

# ì™¸ë¶€ ìŠ¤í¬ë¦½íŠ¸ë“¤ import (in-processìš©)
import vision_clip_violence as vc
import vision_vit as vv
import video_slowfast as vsf

# --------------------------------
# ì‹¤í–‰ í™˜ê²½ (venv)
# --------------------------------
PY_TORCH = "/home/jovyan/Capstone2/Im/venv_pt/bin/python"
PY_TF    = "/home/jovyan/Capstone2/Im/venv_tf/bin/python"

VIDEO_SPLIT_PY  = os.path.join(SCRIPT_DIR, "video_split.py")
AUDIO_YAMNET_PY = os.path.join(SCRIPT_DIR, "audio_yamnet.py")
TEXT_OCR_PY     = os.path.join(SCRIPT_DIR, "text_toxic.py")
FUSION_PY       = os.path.join(SCRIPT_DIR, "fusion_scores.py")  # YOLO ì—†ëŠ” ë²„ì „

# í”„ë ˆì„ ì„œë¸Œí´ë” ì´ë¦„ (ì‚¬ëŒë³„ FRAMES_ROOT ì•„ë˜ì— ìƒì„±)
H_FRAMES_SUBDIR = "ë¹„ë””ì˜¤"
S_FRAMES_SUBDIR = "ì•ˆì „ë¹„ë””ì˜¤"

# ì „ì—­(ì‚¬ëŒë³„ë¡œ mainì—ì„œ ë°”ë€œ)
HARM_VIDEO_DIR = None
SAFE_VIDEO_DIR = None
LABEL_DIR      = None
FRAMES_ROOT    = None


# =========================================
# ê³µìš© ìœ í‹¸
# =========================================
def run(cmd, env=None):
    print("â–¶", " ".join(str(x) for x in cmd))
    p = subprocess.run(cmd, env=env)
    if p.returncode != 0:
        raise RuntimeError("Command failed: " + " ".join(str(x) for x in cmd))


def load_json(path, default=None):
    if default is None:
        default = {}
    if not os.path.exists(path):
        return default
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return default

def save_json(path, data):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    print(f"ğŸ’¾ saved -> {path}")


def backup_if_needed(path):
    """ì‹¤ìˆ˜ ë°©ì§€ìš© ë°±ì—…: ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ .bak í•œ ë²ˆë§Œ ìƒì„±"""
    if os.path.exists(path):
        bak = path + ".bak"
        if not os.path.exists(bak):
            os.rename(path, bak)
            print(f"ğŸ“¦ backup created: {bak}")


def find_category(cat_dict, key):
    """
    ì‚¬ëŒì´ ë§Œë“  categorized JSON(cat_dict) ì•ˆì—ì„œ keyì— í•´ë‹¹í•˜ëŠ” category ì •ë³´ ì°¾ê¸°.
    - 1ìˆœìœ„: key ì™„ì „ ì¼ì¹˜
    - 2ìˆœìœ„: basename ì™„ì „ ì¼ì¹˜
    - 3ìˆœìœ„: key / basename ì´ cat_dictì˜ keyì— ë¶€ë¶„ í¬í•¨
    """
    if key in cat_dict:
        return cat_dict[key]

    base = os.path.basename(key)

    # basename ì™„ì „ ì¼ì¹˜
    for k, v in cat_dict.items():
        if base == os.path.basename(k):
            return v

    # ë¶€ë¶„ í¬í•¨
    for k, v in cat_dict.items():
        if key in k or base in k:
            return v

    return None


def extract_category_value(cat_info):
    """
    cat_infoì—ì„œ ì‹¤ì œ category ë¬¸ìì—´ êº¼ë‚´ê¸°.
    ì˜ˆ: {"label": 1, "category": "weapon"} í˜•íƒœë¥¼ ê¸°ë³¸ìœ¼ë¡œ ê°€ì •.
    êµ¬ì¡°ê°€ ë‹¤ë¥´ë©´ ì—¬ê¸°ì„œ í‚¤ ì´ë¦„ë§Œ ë§ì¶°ì£¼ë©´ ë¨.
    """
    if not isinstance(cat_info, dict):
        return None

    if "category" in cat_info:
        return cat_info["category"]

    # í˜¹ì‹œ ë‹¤ë¥¸ í‚¤ëª… ì¼ìœ¼ë©´ ì—¬ê¸° ì¶”ê°€
    for k in ["Category", "cat", "ì¹´í…Œê³ ë¦¬"]:
        if k in cat_info:
            return cat_info[k]

    return None

def round5(x):
    return round(float(x), 5)


# =========================================
# ğŸ”¥ In-process ëª¨ë¸ ìºì‹œ (CLIP / ViT / SlowFast)
# =========================================
CLIP_MODEL = None
CLIP_PROCESSOR = None
VIT_MODEL = None
VIT_PROCESSOR = None
SLOWFAST_MODEL = None
SLOWFAST_LABELS = None
SLOWFAST_TRANSFORM = T.Resize((224, 224))

if torch.cuda.is_available():
    CLIP_DEVICE = "cuda:0"
    VIT_DEVICE = "cuda:0"
    SLOWFAST_DEVICE = "cuda"
else:
    CLIP_DEVICE = VIT_DEVICE = SLOWFAST_DEVICE = "cpu"


def ensure_clip_model():
    global CLIP_MODEL, CLIP_PROCESSOR
    if CLIP_MODEL is None or CLIP_PROCESSOR is None:
        CLIP_MODEL, CLIP_PROCESSOR = vc.load_model(CLIP_DEVICE)


def ensure_vit_model():
    global VIT_MODEL, VIT_PROCESSOR
    if VIT_MODEL is None or VIT_PROCESSOR is None:
        VIT_PROCESSOR, VIT_MODEL = vv.load_model(VIT_DEVICE)


def ensure_slowfast_model():
    global SLOWFAST_MODEL, SLOWFAST_LABELS
    if SLOWFAST_MODEL is None:
        SLOWFAST_MODEL = vsf.load_slowfast_model(SLOWFAST_DEVICE)
        num_classes = 400  # Kinetics-400
        SLOWFAST_LABELS = vsf.load_kinetics_labels(vsf.KINETICS_LABELS_PATH, num_classes)


# =========================================
# CLIP / ViT / SlowFast in-process ë˜í¼
# =========================================
def run_clip_inprocess(frames_dir: str, out_path: str, batch: int = 16, stride: int = 10):
    # ğŸ” frames_dir í•˜ìœ„ ëª¨ë“  í´ë”ê¹Œì§€ ì¬ê·€ íƒìƒ‰
    pattern = os.path.join(frames_dir, "**", "*")
    imgs = sorted(
        p
        for p in glob(pattern, recursive=True)
        if p.lower().endswith((".jpg", ".jpeg", ".png"))
    )
    num_total = len(imgs)
    if num_total == 0:
        print("âš ï¸ No frames found for CLIP.")
        result = {
            "model": "openai/clip-vit-base-patch32",
            "frames_dir": frames_dir,
            "num_frames_total": 0,
            "num_frames_used": 0,
            "prompts": {
                "harmful": vc.HARMFUL_PROMPTS,
                "benign": vc.BENIGN_PROMPTS,
            },
            "per_frame": {},
            "overall": {
                "avg_violence_prob": 0.0,
                "max_violence_prob": 0.0,
                "p95_violence_prob": 0.0,
            },
        }
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        json.dump(result, open(out_path, "w"), indent=2, ensure_ascii=False)
        print(f"âœ… CLIP saved -> {out_path}")
        return

    # âœ… ê· ë“± 32í”„ë ˆì„ ìƒ˜í”Œë§
    TARGET = 32
    if num_total <= TARGET:
        imgs_used = imgs[:]  # ì „ë¶€ ì‚¬ìš©
    else:
        indices = np.linspace(0, num_total - 1, TARGET, dtype=int)
        imgs_used = [imgs[i] for i in indices]

    num_used = len(imgs_used)
    print(f"ğŸ–¼  CLIP: {num_total} frames ì¤‘ ê· ë“± ìƒ˜í”Œë§ {num_used}ê°œ ì‚¬ìš© (target={TARGET})")

    ensure_clip_model()
    per_frame = vc.compute_clip_scores(
        CLIP_MODEL,
        CLIP_PROCESSOR,
        imgs_used,
        CLIP_DEVICE,
        batch_size=batch,
        temperature=2.0,
    )

    if per_frame:
        vals = [v["violence_prob"] for v in per_frame.values()]
        avg_v = float(np.mean(vals))
        max_v = float(np.max(vals))
        p95_v = float(np.percentile(vals, 95))
    else:
        avg_v = max_v = p95_v = 0.0

    result = {
        "model": "openai/clip-vit-base-patch32",
        "frames_dir": frames_dir,
        "num_frames_total": num_total,
        "num_frames_used": num_used,
        "prompts": {
            "harmful": vc.HARMFUL_PROMPTS,
            "benign": vc.BENIGN_PROMPTS,
        },
        "per_frame": per_frame,
        "overall": {
            "avg_violence_prob": avg_v,
            "max_violence_prob": max_v,
            "p95_violence_prob": p95_v,
        },
    }

    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    print(
        f"âœ… CLIP saved -> {out_path} | "
        f"avg={avg_v:.3f}, max={max_v:.3f}, p95={p95_v:.3f}"
    )



def run_vit_inprocess(frames_dir: str, out_path: str, batch: int = 16, stride: int = 10):
    # ğŸ” frames_dir í•˜ìœ„ ì „ì²´ì—ì„œ ì´ë¯¸ì§€ ì¬ê·€ íƒìƒ‰
    pattern = os.path.join(frames_dir, "**", "*")
    imgs = sorted(
        p
        for p in glob(pattern, recursive=True)
        if p.lower().endswith((".jpg", ".jpeg", ".png"))
    )

    num_total = len(imgs)
    if num_total == 0:
        print("âš ï¸ No frames found for ViT violence.")
        result = {
            "model": vv.MODEL_ID,
            "frames_dir": frames_dir,
            "num_frames_total": 0,
            "num_frames_used": 0,
            "per_frame": {},
            "overall": {
                "avg_violence_prob": 0.0,
                "max_violence_prob": 0.0,
                "p95_violence_prob": 0.0,
            },
        }
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        json.dump(result, open(out_path, "w"), indent=2, ensure_ascii=False)
        print(f"âœ… ViT violence saved -> {out_path}")
        return

    # âœ… ê· ë“± 32í”„ë ˆì„ ìƒ˜í”Œë§
    TARGET = 32
    if num_total <= TARGET:
        imgs_used = imgs[:]
    else:
        indices = np.linspace(0, num_total - 1, TARGET, dtype=int)
        imgs_used = [imgs[i] for i in indices]

    num_used = len(imgs_used)
    print(f"ğŸ–¼  ViT Violence: {num_total} frames ì¤‘ ê· ë“± ìƒ˜í”Œë§ {num_used}ê°œ ì‚¬ìš© (target={TARGET})")

    ensure_vit_model()
    per_frame = vv.compute_violence_scores(
        VIT_PROCESSOR,
        VIT_MODEL,
        imgs_used,
        device=VIT_DEVICE,
        batch_size=batch,
    )

    if per_frame:
        vals = [v["violence_prob"] for v in per_frame.values()]
        avg_v = float(np.mean(vals))
        max_v = float(np.max(vals))
        p95_v = float(np.percentile(vals, 95))
    else:
        avg_v = max_v = p95_v = 0.0

    result = {
        "model": vv.MODEL_ID,
        "frames_dir": frames_dir,
        "num_frames_total": num_total,
        "num_frames_used": num_used,
        "per_frame": per_frame,
        "overall": {
            "avg_violence_prob": avg_v,
            "max_violence_prob": max_v,
            "p95_violence_prob": p95_v,
        },
    }

    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    print(
        f"âœ… ViT violence saved -> {out_path} | "
        f"avg={avg_v:.3f}, max={max_v:.3f}, p95={p95_v:.3f}"
    )


def run_slowfast_inprocess(frames_dir: str, out_path: str, frames_per_clip: int = 32, fps: float = 30.0):
    ensure_slowfast_model()

    # ğŸ” frames_dir í•˜ìœ„ì˜ ëª¨ë“  jpgë¥¼ ì¬ê·€ íƒìƒ‰ (full path)
    pattern = os.path.join(frames_dir, "**", "*.jpg")
    all_frames = sorted(glob(pattern, recursive=True))
    num = len(all_frames)
    if num == 0:
        print("âš ï¸ No frames found in:", frames_dir)
        json.dump(
            {
                "model": "slowfast_r101",
                "frames_dir": frames_dir,
                "frames_per_clip": frames_per_clip,
                "clip_sec": float(frames_per_clip / fps) if fps > 0 else 2.0,
                "clips": [],
                "overall": {
                    "num_clips": 0,
                    "avg_top1_prob": 0.0,
                    "max_top1_prob": 0.0,
                    "avg_violence_hint": 0.0,
                    "max_violence_hint": 0.0,
                },
            },
            open(out_path, "w"),
            indent=2,
            ensure_ascii=False,
        )
        print(f"âœ… SlowFast saved -> {out_path}")
        return

    F = frames_per_clip

    # ğŸ¯ ì „ì²´ ì˜ìƒ ê¸¸ì´ (ì´ˆ) ì¶”ì •
    if fps and fps > 0:
        duration = num / fps
        clip_sec = duration  # ì´ 32í”„ë ˆì„ì´ ì „ì²´ ì˜ìƒì„ ëŒ€í‘œí•œë‹¤ê³  ë³´ê³  ì „ì²´ ê¸¸ì´ë¥¼ ì‚¬ìš©
        print(f"[SlowFast] fps={fps} / frames={num} â†’ duration={duration:.4f} sec")
    else:
        duration = 0.0
        clip_sec = float(F / 30.0)  # fallback
        print(f"[SlowFast] Using fallback clip_sec={clip_sec}")

    slowfast = SLOWFAST_MODEL
    labels = SLOWFAST_LABELS
    transform = SLOWFAST_TRANSFORM

    clips_out = []
    top1_list = []
    violence_list = []

    # âœ… ê· ë“± 32í”„ë ˆì„ ìƒ˜í”Œë§
    if num <= F:
        sample_paths = all_frames[:]  # ì „ë¶€ ì‚¬ìš©
    else:
        indices = np.linspace(0, num - 1, F, dtype=int)
        sample_paths = [all_frames[i] for i in indices]

    # í•˜ë‚˜ì˜ clip ìƒì„±
    frames = vsf.load_frames(sample_paths)  # [T,C,H,W]
    frames = torch.stack([transform(fr) for fr in frames])  # [T,C,224,224]

    slow_pathway, fast_pathway = vsf.slowfast_transform(frames)

    slow_pathway = slow_pathway.unsqueeze(0).to(SLOWFAST_DEVICE)
    fast_pathway = fast_pathway.unsqueeze(0).to(SLOWFAST_DEVICE)

    inp = [slow_pathway, fast_pathway]

    with torch.no_grad():
        out = slowfast(inp)

    prob = torch.softmax(out, dim=1)[0]

    top5 = torch.topk(prob, 5)
    top_idx = top5.indices.cpu().tolist()
    top_prob = top5.values.cpu().tolist()

    topk_data = []
    top1_prob = float(top_prob[0])
    top1_list.append(top1_prob)

    violence_hint = 0.0

    for idx, p in zip(top_idx, top_prob):
        label = labels[idx].lower() if idx < len(labels) else f"class_{idx}"
        p_float = float(p)

        topk_data.append({
            "index": idx,
            "label": label,
            "prob": p_float,
        })

        if any(k in label for k in vsf.VIOLENCE_KEYWORDS):
            violence_hint = max(violence_hint, p_float)

    violence_list.append(violence_hint)

    clips_out.append({
        "index": 0,
        "start_sec": 0.0,
        "end_sec": float(clip_sec),
        "topk": topk_data,
        "top1_prob": top1_prob,
        "violence_hint": violence_hint,
    })

    if clips_out:
        avg_top1 = float(sum(top1_list) / len(top1_list))
        max_top1 = float(max(top1_list))
        avg_viol = float(sum(violence_list) / len(violence_list))
        max_viol = float(max(violence_list))
    else:
        avg_top1 = max_top1 = avg_viol = max_viol = 0.0

    out_json = {
        "model": "slowfast_r101",
        "frames_dir": frames_dir,
        "frames_per_clip": frames_per_clip,
        "clip_sec": clip_sec,
        "clips": clips_out,
        "overall": {
            "num_clips": len(clips_out),  # ë³´í†µ 1
            "avg_top1_prob": avg_top1,
            "max_top1_prob": max_top1,
            "avg_violence_hint": avg_viol,
            "max_violence_hint": max_viol,
        },
    }

    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    json.dump(out_json, open(out_path, "w"), indent=2, ensure_ascii=False)
    print(f"âœ… SlowFast saved -> {out_path}")



# =========================================
# 1) ìë™ ë¼ë²¨ ìƒì„± (ì‚¬ëŒë³„ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
# =========================================
# def auto_generate_video_labels():
    # ìƒëŒ€ê²½ë¡œ( category/clip_001.mp4 ì´ëŸ° ì‹ ) ë¦¬ìŠ¤íŠ¸
    harm_files = get_all_videos(HARM_VIDEO_DIR)
    safe_files = get_all_videos(SAFE_VIDEO_DIR)

    # keyë¥¼ ìƒëŒ€ê²½ë¡œë¡œ ì‚¬ìš© (ë‚˜ì¤‘ì— HARM_VIDEO_DIR/Safeì™€ í•©ì³ì„œ full pathë¡œ ì”€)
    verified_video_labels = {f: 1 for f in harm_files}
    safe_video_labels     = {f: 0 for f in safe_files}

    json.dump(
        verified_video_labels,
        open(os.path.join(LABEL_DIR, "verified_video_labels_init.json"), "w", encoding="utf-8"),
        indent=2,
        ensure_ascii=False,
    )
    json.dump(
        safe_video_labels,
        open(os.path.join(LABEL_DIR, "safe_video_labels_init.json"), "w", encoding="utf-8"),
        indent=2,
        ensure_ascii=False,
    )

    print(f"ğŸ”¹ ë¹„ë””ì˜¤ ìë™ ë¼ë²¨ ìƒì„±: harmful={len(verified_video_labels)}, safe={len(safe_video_labels)}")

    return verified_video_labels, safe_video_labels


# =========================================
# 2) í•œ ì˜ìƒ ì²˜ë¦¬
# =========================================
def process_one_video(video_path, kind: str):
    """
    kind: "harm" ë˜ëŠ” "safe"
    FRAMES_ROOT / (ë¹„ë””ì˜¤ | ì•ˆì „ë¹„ë””ì˜¤) / <ìƒëŒ€ê²½ë¡œ ê¸°ë°˜ ì´ë¦„> ì— í”„ë ˆì„ ì €ì¥
    """
    # ì–´ë–¤ root ê¸°ì¤€ì¸ì§€ ê²°ì •
    if kind == "safe":
        root = SAFE_VIDEO_DIR
        subdir = S_FRAMES_SUBDIR
    else:
        root = HARM_VIDEO_DIR
        subdir = H_FRAMES_SUBDIR

    # root ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ: category1/clip_001.mp4 ì´ëŸ° í˜•íƒœ
    rel = os.path.relpath(video_path, root)
    rel_stem, _ = os.path.splitext(rel)           # category1/clip_001
    safe_stem = rel_stem.replace(os.sep, "__")    # category1__clip_001

    video_name = os.path.basename(video_path)     # ë¡œê·¸ìš©

    frames_dir = os.path.join(FRAMES_ROOT, subdir, safe_stem)
    os.makedirs(frames_dir, exist_ok=True)

    FRAMES_JSON   = os.path.join(frames_dir, "meta.json")
    CLIP_JSON     = os.path.join(frames_dir, "clip_result.json")
    VIT_JSON      = os.path.join(frames_dir, "vit_result.json")
    AUDIO_WAV     = os.path.join(frames_dir, f"{safe_stem}_audio.wav")
    AUDIO_JSON    = os.path.join(frames_dir, "audio_result.json")
    TEXT_JSON     = os.path.join(frames_dir, "text_result.json")
    SLOWFAST_JSON = os.path.join(frames_dir, "slowfast_result.json")
    FUSED_JSON    = os.path.join(frames_dir, "fusion_result.json")

    # 1) ë¹„ë””ì˜¤ â†’ í”„ë ˆì„ split
    run([
        PY_TORCH, VIDEO_SPLIT_PY,
        "--video", video_path,
        "--out", frames_dir,
        "--clip-sec", "2",
    ])

    meta = load_json(FRAMES_JSON, {})
    meta_meta = meta.get("meta", {}) if isinstance(meta.get("meta", {}), dict) else meta

    fps = meta_meta.get("fps", 30.0)
    try:
        fps = float(fps)
    except:
        fps = 30.0

    orig_total_frames = meta_meta.get("orig_total_frames") or meta_meta.get("total_frames_saved") or meta_meta.get("frames") or 0
    try:
        orig_total_frames = int(orig_total_frames)
    except:
        orig_total_frames = 0

    if "duration" in meta_meta:
        try:
            duration = float(meta_meta["duration"])
        except:
            duration = float(orig_total_frames) / fps if fps > 0 and orig_total_frames > 0 else 0.0
    else:
        duration = float(orig_total_frames) / fps if fps > 0 and orig_total_frames > 0 else 0.0

    total_frames = orig_total_frames

    print(f"[{video_name}] fps = {fps}")

    # 2) CLIP
    run_clip_inprocess(
        frames_dir=frames_dir,
        out_path=CLIP_JSON,
        batch=16,
        stride=10,
    )

    # 3) ViT
    run_vit_inprocess(
        frames_dir=frames_dir,
        out_path=VIT_JSON,
        batch=16,
        stride=10,
    )

    # 4) Audio + YAMNet
    audio_ok = False
    if not os.path.exists(AUDIO_WAV):
        cmd = [
            "ffmpeg", "-hide_banner", "-nostdin",
            "-i", video_path, "-ac", "1", "-ar", "16000", "-vn",
            AUDIO_WAV, "-y",
        ]
        print("â–¶", " ".join(cmd))
        p = subprocess.run(cmd)
        if p.returncode == 0 and os.path.exists(AUDIO_WAV):
            audio_ok = True
        else:
            print(f"âš ï¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì´ ì—†ì–´ì„œ YAMNet ìŠ¤í‚µ: {video_path}")
    else:
        audio_ok = True

    if audio_ok:
        tf_env = os.environ.copy()
        tf_env["CUDA_VISIBLE_DEVICES"] = "-1"
        tf_env["TF_ENABLE_ONEDNN_OPTS"] = "0"
        tf_env["TF_CPP_MIN_LOG_LEVEL"] = "2"

        run([
            PY_TF, AUDIO_YAMNET_PY,
            "--audio", AUDIO_WAV,
            "--out", AUDIO_JSON,
        ], env=tf_env)
    else:
        dummy_audio = {
            "overall": {
                "violent_audio_prob": 0.0,
                "has_audio": False,
            }
        }
        with open(AUDIO_JSON, "w", encoding="utf-8") as f:
            json.dump(dummy_audio, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ dummy audio_result.json ìƒì„± -> {AUDIO_JSON}")

    # 5) TEXT (OCR + Toxic)
    frame_imgs = [
        f for f in os.listdir(frames_dir)
        if f.lower().endswith((".jpg", ".jpeg", ".png"))
    ]
    frame_imgs.sort()

    text_ok = False
    if frame_imgs:
        first_frame = os.path.join(frames_dir, frame_imgs[0])
        try:
            run([
                PY_TORCH,
                TEXT_OCR_PY,
                "--image", first_frame,
                "--out", TEXT_JSON,
            ])
            if os.path.exists(TEXT_JSON):
                text_ok = True
        except RuntimeError:
            print(f"âš ï¸ í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨, dummyë¡œ ëŒ€ì²´: {video_path}")
            text_ok = False
    else:
        print(f"âš ï¸ í”„ë ˆì„ ì´ë¯¸ì§€ê°€ ì—†ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ ìŠ¤í‚µ: {video_path}")

    if not text_ok:
        dummy_text = {
            "overall": {
                "hate_prob": 0.0,
                "sexual_text_prob": 0.0,
                "has_text": False,
            }
        }
        with open(TEXT_JSON, "w", encoding="utf-8") as f:
            json.dump(dummy_text, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ dummy text_result.json ìƒì„± -> {TEXT_JSON}")

    # 6) SlowFast
    run_slowfast_inprocess(
        frames_dir=frames_dir,
        out_path=SLOWFAST_JSON,
        frames_per_clip=32,
        fps=fps,
    )

    # 7) Fusion
    run([
        PY_TORCH, FUSION_PY,
        "--clip", CLIP_JSON,
        "--vit", VIT_JSON,
        "--audio", AUDIO_JSON,
        "--text", TEXT_JSON,
        "--slowfast", SLOWFAST_JSON,
        "--out", FUSED_JSON,
    ])

    fused = load_json(FUSED_JSON, {})
    violence_prob = float(
        fused.get("overall", {}).get(
            "violence_prob",
            fused.get("scores", {}).get("final", 0.0),
        )
    )

    # CLIP ì‚¬ìš© í”„ë ˆì„ ìˆ˜
    clip_meta = load_json(CLIP_JSON, {})
    sampled_frames = 0

    if "num_frames_used" in clip_meta:
        try:
            sampled_frames = int(clip_meta["num_frames_used"])
        except:
            sampled_frames = 0

    if sampled_frames == 0 and isinstance(clip_meta.get("per_frame"), dict):
        sampled_frames = len(clip_meta["per_frame"])

    if sampled_frames == 0:
        meta_clip = clip_meta.get("meta", {})
        if isinstance(meta_clip, dict) and "sampled_frames" in meta_clip:
            try:
                sampled_frames = int(meta_clip["sampled_frames"])
            except:
                sampled_frames = 0

    if sampled_frames == 0 and "frames" in clip_meta and isinstance(clip_meta["frames"], list):
        sampled_frames = len(clip_meta["frames"])

    # SlowFast ëŒ€í‘œ í–‰ë™
    slow_json = load_json(SLOWFAST_JSON, {})
    estimated_action = None
    clips = slow_json.get("clips") or []
    if clips:
        labels = []
        for c in clips:
            topk = c.get("topk") or []
            if topk:
                labels.append(topk[0].get("label"))
        if labels:
            estimated_action = Counter(labels).most_common(1)[0][0]
    if not estimated_action:
        estimated_action = "unknown"

    violence_prob = round5(violence_prob)
    print(f"[{video_name}] ğŸ”¥ violence_prob = {violence_prob}")

    video_stats = {
        "duration": duration,
        "fps": fps,
        "total_frames": total_frames,
        "sampled_frames": sampled_frames,
        "estimated_action": estimated_action,
    }

    return violence_prob, video_stats


# =========================================
# 3) ìµœì¢… ë¼ë²¨ ê°±ì‹  (í•˜ë‚˜ì˜ ì‚¬ëŒ ê¸°ì¤€)
# =========================================
# def merge_scores_and_update_video_labels(verified, safe):
    TH = 0.63

    # ìœ í•´ ë¹„ë””ì˜¤
    for fname in verified.keys():
        video_path = os.path.join(HARM_VIDEO_DIR, fname)
        score, stats = process_one_video(video_path, kind="harm")
        pred = 1 if score >= TH else 0

        verified[fname] = {
            "duration": stats["duration"],
            "fps": stats["fps"],
            "total_frames": stats["total_frames"],
            "sampled_frames": stats["sampled_frames"],
            "estimated_action": stats["estimated_action"],
            "is_harmful": True,
            "label": 1,
            "pred_label": pred,
            "violence_prob": score,
        }

    # ì•ˆì „ ë¹„ë””ì˜¤
    for fname in safe.keys():
        video_path = os.path.join(SAFE_VIDEO_DIR, fname)
        score, stats = process_one_video(video_path, kind="safe")
        pred = 1 if score >= TH else 0

        category = "safe" if pred == 0 else "review"

        safe[fname] = {
            "is_safe": True,
            "label": 0,
            "pred_label": pred,
            "category": category,
            "duration": stats["duration"],
            "fps": stats["fps"],
            "total_frames": stats["total_frames"],
            "sampled_frames": stats["sampled_frames"],
            "estimated_action": stats["estimated_action"],
            "violence_prob": score,
        }

    json.dump(
        verified,
        open(os.path.join(LABEL_DIR, "verified_video_labels.json"), "w", encoding="utf-8"),
        indent=2,
        ensure_ascii=False,
    )

    json.dump(
        safe,
        open(os.path.join(LABEL_DIR, "safe_video_labels.json"), "w", encoding="utf-8"),
        indent=2,
        ensure_ascii=False,
    )

    print("âœ… ë¹„ë””ì˜¤ ë¼ë²¨ ì €ì¥ ì™„ë£Œ ")


# =========================================
# ì‚¬ëŒ í•œ ëª… ì²˜ë¦¬
# =========================================
# def process_person(person_name: str):
#     global HARM_VIDEO_DIR, SAFE_VIDEO_DIR, LABEL_DIR, FRAMES_ROOT

#     print("\n==============================")
#     print(f"ğŸ¬ ë¹„ë””ì˜¤ í…ŒìŠ¤íŠ¸ ì‹œì‘: {person_name}")
#     print("==============================")

#     person_src = os.path.join(SRC_ROOT, person_name)

#     # harmful ë¹„ë””ì˜¤ í´ë” í›„ë³´
#     harm_candidates = ["ë¹„ë””ì˜¤", "video", "Video"]
#     harm_dir = None
#     for c in harm_candidates:
#         p = os.path.join(person_src, c)
#         if os.path.exists(p):
#             harm_dir = p
#             break
#     if harm_dir is None:
#         raise FileNotFoundError(f"âŒ harmful ë¹„ë””ì˜¤ í´ë” ì—†ìŒ: {harm_candidates}")

#     # safe ë¹„ë””ì˜¤ í´ë” í›„ë³´
#     safe_candidates = ["ì•ˆì „ë¹„ë””ì˜¤", "ì•ˆì „_ë¹„ë””ì˜¤", "safe_video", "safe", "Safe"]
#     safe_dir = None
#     for c in safe_candidates:
#         p = os.path.join(person_src, c)
#         if os.path.exists(p):
#             safe_dir = p
#             break
#     if safe_dir is None:
#         raise FileNotFoundError(f"âŒ safe ë¹„ë””ì˜¤ í´ë” ì—†ìŒ: {safe_candidates}")

#     # ì „ì—­ ê°±ì‹ 
#     HARM_VIDEO_DIR = harm_dir
#     SAFE_VIDEO_DIR = safe_dir

#     person_out = os.path.join(OUT_ROOT, person_name)
#     LABEL_DIR = os.path.join(person_out, "ë¼ë²¨_ê²°ê³¼")
#     FRAMES_ROOT = os.path.join(person_out, "video_frames")

#     os.makedirs(LABEL_DIR, exist_ok=True)
#     os.makedirs(FRAMES_ROOT, exist_ok=True)

#     print(f"ğŸ“‚ harmful dir: {HARM_VIDEO_DIR}")
#     print(f"ğŸ“‚ safe   dir: {SAFE_VIDEO_DIR}")
#     print(f"ğŸ“‚ label  dir: {LABEL_DIR}")
#     print(f"ğŸ“‚ frames dir: {FRAMES_ROOT}")

#     verified, safe = auto_generate_video_labels()
#     merge_scores_and_update_video_labels(verified, safe)

#     print(f"ğŸ‰ {person_name} ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ!\n")
def process_person(person_name: str):
    """
    ì‚¬ëŒë³„ë¡œ:
      1) person_name_labels_categorized.jsonì„ ì½ì–´ì„œ
      2) category == 'safe' -> label=0, ê·¸ ì™¸ -> label=1 (ì •ë‹µ)
      3) ì •ë‹µì´ ìˆëŠ” ë¹„ë””ì˜¤ì—ë§Œ ëª¨ë¸ ì‹¤í–‰ (process_one_video)
      4) ê²°ê³¼ë¥¼ verified_video_labels.json / safe_video_labels.json ì— ì €ì¥
    """
    global HARM_VIDEO_DIR, SAFE_VIDEO_DIR, LABEL_DIR, FRAMES_ROOT

    print("\n==============================")
    print(f"ğŸ¬ ë¹„ë””ì˜¤ í‰ê°€ ì‹œì‘(ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ GT): {person_name}")
    print("==============================")

    # 0) ê²½ë¡œ ì„¤ì •
    person_src = os.path.join(SRC_ROOT, person_name)

    # harmful / safe ë¹„ë””ì˜¤ í´ë” (ë¬¼ë¦¬ì  ìœ„ì¹˜ìš©, ì˜ë¯¸ëŠ” ì´ì œ GTì— ì•ˆ ì”€)
    harm_candidates = ["ë¹„ë””ì˜¤", "video", "Video"]
    safe_candidates = ["ì•ˆì „ë¹„ë””ì˜¤", "ì•ˆì „_ë¹„ë””ì˜¤", "safe_video", "safe", "Safe"]

    harm_dir = None
    for c in harm_candidates:
        p = os.path.join(person_src, c)
        if os.path.exists(p):
            harm_dir = p
            break

    safe_dir = None
    for c in safe_candidates:
        p = os.path.join(person_src, c)
        if os.path.exists(p):
            safe_dir = p
            break

    if harm_dir is None and safe_dir is None:
        raise FileNotFoundError(f"âŒ {person_name}: ë¹„ë””ì˜¤ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")

    HARM_VIDEO_DIR = harm_dir
    SAFE_VIDEO_DIR = safe_dir

    person_out = os.path.join(OUT_ROOT, person_name)
    LABEL_DIR = os.path.join(person_out, "ë¼ë²¨_ê²°ê³¼")
    FRAMES_ROOT = os.path.join(person_out, "video_frames")

    os.makedirs(LABEL_DIR, exist_ok=True)
    os.makedirs(FRAMES_ROOT, exist_ok=True)

    print(f"ğŸ“‚ person_src: {person_src}")
    if HARM_VIDEO_DIR:
        print(f"ğŸ“‚ harm dir : {HARM_VIDEO_DIR}")
    if SAFE_VIDEO_DIR:
        print(f"ğŸ“‚ safe dir : {SAFE_VIDEO_DIR}")
    print(f"ğŸ“‚ label dir: {LABEL_DIR}")
    print(f"ğŸ“‚ frames dir: {FRAMES_ROOT}")

    # 1) ì‚¬ëŒì´ ë§Œë“  category JSON (ì •ë‹µ ì •ë³´)
    categ_path = os.path.join(
        CATEG_ROOT,
        f"{person_name}_labels_categorized.json"
    )
    cat_dict = load_json(categ_path, {})
    if not cat_dict:
        print(f"âš ï¸ {person_name}: ì¹´í…Œê³ ë¦¬ JSONì´ ë¹„ì–´ìˆê±°ë‚˜ ì—†ìŒ â†’ {categ_path}")
        print("   â†’ ì´ ì‚¬ëŒì€ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
        return

    print(f"ğŸ“„ ì¹´í…Œê³ ë¦¬ JSON ë¡œë“œ ì™„ë£Œ: {categ_path} (keys={len(cat_dict)})")

    # 2) ì´ ì‚¬ëŒ í´ë” ì•„ë˜ ëª¨ë“  ë¹„ë””ì˜¤ ëª©ë¡ ìˆ˜ì§‘
    all_video_paths = []

    search_roots = []
    if HARM_VIDEO_DIR:
        search_roots.append(HARM_VIDEO_DIR)
    if SAFE_VIDEO_DIR and SAFE_VIDEO_DIR not in search_roots:
        search_roots.append(SAFE_VIDEO_DIR)
    if not search_roots:
        # í˜¹ì‹œ ë‘˜ ë‹¤ ëª» ì°¾ì•˜ìœ¼ë©´ person_src ì „ì²´ë¥¼ ë’¤ì§„ë‹¤
        search_roots = [person_src]

    for root in search_roots:
        for dirpath, _, filenames in os.walk(root):
            for f in filenames:
                if f.lower().endswith(VIDEO_EXTS):
                    full = os.path.join(dirpath, f)
                    all_video_paths.append(full)

    all_video_paths = sorted(set(all_video_paths))
    print(f"ğŸ” ë°œê²¬í•œ ë¹„ë””ì˜¤ ê°œìˆ˜: {len(all_video_paths)}")

    # 3) í‰ê°€ ê²°ê³¼ë¥¼ ë‹´ì„ dict (GTì— ë”°ë¼ ë‚˜ëˆ”)
    verified = {}  # label=1 (ìœ í•´)
    safe = {}      # label=0 (ì•ˆì „)

    TH = 0.63  # violence_prob threshold

    # 4) ê° ë¹„ë””ì˜¤ì— ëŒ€í•´:
    #    - categ JSONì—ì„œ category ì°¾ê¸°
    #    - category -> GT label(0/1) ê²°ì •
    #    - ì •ë‹µì´ ìˆëŠ” ë¹„ë””ì˜¤ì—ë§Œ ëª¨ë¸ ì‹¤í–‰
    for video_path in all_video_paths:
        # ì‚¬ëŒ í´ë” ê¸°ì¤€ ìƒëŒ€ê²½ë¡œ (í‚¤ë¡œ ì“°ê¸° ì¢‹ìŒ)
        rel_from_person = os.path.relpath(video_path, person_src)

        # ì‚¬ëŒ ë¼ë²¨ JSONì—ì„œ category ì°¾ê¸°
        cat_info = find_category(cat_dict, rel_from_person)
        if not cat_info:
            # ì¹´í…Œê³ ë¦¬ JSONì— ì—†ìœ¼ë©´ ì´ ë¹„ë””ì˜¤ëŠ” "ì…ë ¥ ì•ˆ ë°›ì€ ê²ƒ" â†’ ìŠ¤í‚µ
            print(f"  âš ï¸ ì¹´í…Œê³ ë¦¬ ì—†ìŒ, ìŠ¤í‚µ: {rel_from_person}")
            continue

        cat_val = extract_category_value(cat_info)
        if cat_val is None:
            print(f"  âš ï¸ category í•„ë“œ ì—†ìŒ, ìŠ¤í‚µ: {rel_from_person} -> {cat_info}")
            continue

        cat_str = str(cat_val).lower()

        # âœ… ì •ë‹µ ë¼ë²¨ ê²°ì •: category == 'safe' â†’ 0, ê·¸ ì™¸ â†’ 1
        is_safe = (cat_str == "safe")
        gt_label = 0 if is_safe else 1

        # frames ë””ë ‰í† ë¦¬ êµ¬ì¡°ìš© kind (ì •ë‹µ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ì)
        kind = "safe" if is_safe else "harm"

        print(f"\nğŸ¥ ë¹„ë””ì˜¤ ì²˜ë¦¬: {rel_from_person}")
        print(f"   - category: {cat_val} â†’ GT label={gt_label} ({'safe' if is_safe else 'harmful'})")

        # 5) ëª¨ë¸ ì‹¤í–‰
        score, stats = process_one_video(video_path, kind=kind)
        pred = 1 if score >= TH else 0

        info = {
            "category": cat_val,
            "label": gt_label,          # âœ… ì •ë‹µ (ì‚¬ëŒ ë¼ë²¨)
            "pred_label": pred,         # âœ… ëª¨ë¸ ì˜ˆì¸¡
            "violence_prob": score,     # ëª¨ë¸ ì¶œë ¥
            "duration": stats["duration"],
            "fps": stats["fps"],
            "total_frames": stats["total_frames"],
            "sampled_frames": stats["sampled_frames"],
            "estimated_action": stats["estimated_action"],
            "is_safe": is_safe,
            "is_harmful": not is_safe,
        }

        # GTì— ë”°ë¼ ë‘ ê°œ JSONìœ¼ë¡œ ë¶„ë¦¬ ì €ì¥
        if gt_label == 1:
            verified[rel_from_person] = info
        else:
            safe[rel_from_person] = info

        print(
            f"   â†’ violence_prob={score:.3f}, pred_label={pred}, "
            f"{'ì •ë‹µ' if pred == gt_label else 'ì˜¤ë‹µ'}"
        )

    # 6) ê²°ê³¼ ì €ì¥
    verified_path = os.path.join(LABEL_DIR, "verified_video_labels.json")
    safe_path     = os.path.join(LABEL_DIR, "safe_video_labels.json")

    save_json(verified_path, verified)
    save_json(safe_path, safe)

    print(f"\nâœ… {person_name} ë¹„ë””ì˜¤ í‰ê°€ ì™„ë£Œ")
    print(f"   - harmful(ì •ë‹µ=1) ê°œìˆ˜: {len(verified)}")
    print(f"   - safe   (ì •ë‹µ=0) ê°œìˆ˜: {len(safe)}\n")


def update_video_categories_for_person(person_name: str):
    """
    ì‚¬ëŒì´ ë§Œë“  *_labels_categorized.jsonì„ ì½ì–´ì„œ
    ì´ë¯¸ ì¡´ì¬í•˜ëŠ” verified_video_labels.json / safe_video_labels.jsonì—
    category í•„ë“œë§Œ ì¶”ê°€/ê°±ì‹ í•˜ëŠ” ê°€ë²¼ìš´ ìœ í‹¸.
    (ëª¨ë¸ ì‹¤í–‰ X)
    """
    print("\n==============================")
    print(f"ğŸ“ {person_name} ë¹„ë””ì˜¤ category ê°±ì‹  ì‹œì‘ (models X)")
    print("==============================")

    # 1) ì‚¬ëŒë³„ categorized JSON
    categ_path = os.path.join(
        CATEG_ROOT,
        f"{person_name}_labels_categorized.json"
    )
    cat_dict = load_json(categ_path, {})
    if not cat_dict:
        print(f"âš ï¸ {person_name}: ì¹´í…Œê³ ë¦¬ JSONì´ ë¹„ì–´ìˆê±°ë‚˜ ì—†ìŒ â†’ {categ_path}")
    else:
        print(f"ğŸ“„ ì¹´í…Œê³ ë¦¬ JSON ë¡œë“œ ì™„ë£Œ: {categ_path} (keys={len(cat_dict)})")

    # 2) ë¹„ë””ì˜¤ ë¼ë²¨ íŒŒì¼ë“¤
    label_dir = os.path.join(OUT_ROOT, person_name, "ë¼ë²¨_ê²°ê³¼")
    verified_path = os.path.join(label_dir, "verified_video_labels.json")
    safe_path     = os.path.join(label_dir, "safe_video_labels.json")

    verified = load_json(verified_path, {})
    safe     = load_json(safe_path, {})

    if not verified and not safe:
        print(f"âš ï¸ {person_name}: ê¸°ì¡´ ë¹„ë””ì˜¤ ë¼ë²¨ JSONì´ ì—†ì–´ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
        return

    # 3) ì›ë³¸ ë°±ì—…
    backup_if_needed(verified_path)
    backup_if_needed(safe_path)

    # 4) harmful ë¹„ë””ì˜¤ category ê°±ì‹ 
    updated_harm = 0
    for key, info in verified.items():
        cat_info = find_category(cat_dict, key)
        if not cat_info:
            print(f"  âš ï¸ harmful category ë§¤ì¹­ ì‹¤íŒ¨: {key}")
            continue

        cat_val = extract_category_value(cat_info)
        if cat_val is None:
            print(f"  âš ï¸ harmful category ê°’ ì—†ìŒ: {key} -> {cat_info}")
            continue

        if not isinstance(info, dict):
            info = {}
        info["category"] = cat_val
        verified[key] = info
        updated_harm += 1

    # 5) safe ë¹„ë””ì˜¤ category ê°±ì‹ 
    updated_safe = 0
    for key, info in safe.items():
        cat_info = find_category(cat_dict, key)
        if not cat_info:
            print(f"  âš ï¸ safe category ë§¤ì¹­ ì‹¤íŒ¨: {key}")
            continue

        cat_val = extract_category_value(cat_info)
        if cat_val is None:
            print(f"  âš ï¸ safe category ê°’ ì—†ìŒ: {key} -> {cat_info}")
            continue

        if not isinstance(info, dict):
            info = {}
        info["category"] = cat_val
        safe[key] = info
        updated_safe += 1

    # 6) ì €ì¥
    save_json(verified_path, verified)
    save_json(safe_path, safe)

    print(f"âœ… {person_name} category ê°±ì‹  ì™„ë£Œ â†’ harmful={updated_harm}, safe={updated_safe}")
# =========================================
# MAIN
# =========================================
def main():
    people = ["ë°•ìƒì›", "ì•ˆì§€ì‚°", "ì„ì˜ì¬"]

    # ì‚¬ìš©ë²•:
    # 1) ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: python this_script.py
    # 2) categoryë§Œ ê°±ì‹ :       python this_script.py --update-category
    if "--update-category" in sys.argv:
        print("ğŸ”§ MODE: category ì—…ë°ì´íŠ¸ë§Œ ìˆ˜í–‰ (ëª¨ë¸ ì‹¤í–‰ X)")
        for person in people:
            update_video_categories_for_person(person)
        print("\nğŸ‰ ëª¨ë“  ì‚¬ëŒ category ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        return

    # ê¸°ë³¸: ì „ì²´ ë¹„ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    for person in people:
        process_person(person)
    print("\nğŸ‰ ëª¨ë“  ì‚¬ëŒ ë¹„ë””ì˜¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


if __name__ == "__main__":
    main()
