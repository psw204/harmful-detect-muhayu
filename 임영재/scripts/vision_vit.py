#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ViT ê¸°ë°˜ í­ë ¥(violence) ìž¥ë©´ ë¶„ë¥˜
- ëª¨ë¸: jaranohaal/vit-base-violence-detection
- ìž…ë ¥: frames ë””ë ‰í† ë¦¬ì˜ ì´ë¯¸ì§€ë“¤
- ì¶œë ¥: í”„ë ˆìž„ë³„ violence_prob + ì „ì²´ í†µê³„ (avg / max / p95)

JSON ì˜ˆì‹œ:
{
  "model": "jaranohaal/vit-base-violence-detection",
  "frames_dir": "...",
  "num_frames_total": 150,
  "num_frames_used": 15,
  "per_frame": {
    "clip_000_frame_000.jpg": { "violence_prob": 0.013 },
    ...
  },
  "overall": {
    "avg_violence_prob": 0.12,
    "max_violence_prob": 0.84,
    "p95_violence_prob": 0.80
  }
}
"""

import os
import json
import argparse
from glob import glob

os.environ["TRANSFORMERS_NO_TF"] = "1"

import torch
import numpy as np
from PIL import Image
from tqdm import tqdm
from transformers import AutoImageProcessor, ViTForImageClassification
import transformers, warnings

transformers.logging.set_verbosity_error()              # â¬… transformers ì›Œë‹/ë¡œê·¸ ì¤„ì´ê¸°
warnings.filterwarnings("ignore", category=FutureWarning, module="transformers")


BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_ID = "jaranohaal/vit-base-violence-detection"
FINETUNED_PATH = os.path.join(BASE_DIR, "vit_finetuned.pth")  # ë˜ëŠ” ì‹¤ì œ íŒŒì¼ ì´ë¦„

def load_model(device: str):
    print(f"ðŸ” Loading ViT violence model ...")
    processor = AutoImageProcessor.from_pretrained(MODEL_ID)
    model = ViTForImageClassification.from_pretrained(MODEL_ID)

    # ðŸ”¥ íŒŒì¸íŠœë‹ weight ë¡œë“œ (ìžˆìœ¼ë©´)
    if os.path.exists(FINETUNED_PATH):
        print(f"ðŸ”§ Loading fine-tuned weights: {FINETUNED_PATH}")
        state = torch.load(FINETUNED_PATH, map_location=device)
        model.load_state_dict(state, strict=False)
    else:
        print(f"âš ï¸ Fine-tuned weights not found: {FINETUNED_PATH} (base ëª¨ë¸ë¡œ ì§„í–‰)")

    model.to(device)
    model.eval()
    return processor, model

def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument("--frames", required=True, help="í”„ë ˆìž„ ì´ë¯¸ì§€ë“¤ì´ ìžˆëŠ” ë””ë ‰í† ë¦¬")
    ap.add_argument("--out", required=True, help="ì¶œë ¥ JSON ê²½ë¡œ")
    ap.add_argument("--batch", type=int, default=16, help="ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ 16)")
    ap.add_argument(
        "--stride",
        type=int,
        default=10,
        help="í”„ë ˆìž„ ìƒ˜í”Œë§ ê°„ê²© (Nìž¥ ì¤‘ 1ìž¥ë§Œ ì‚¬ìš©, ê¸°ë³¸ 10)",
    )
    ap.add_argument(
        "--device",
        default=None,
        help="cuda:0 ë˜ëŠ” cpu (ê¸°ë³¸: cuda ê°€ëŠ¥í•˜ë©´ cuda:0, ì•„ë‹ˆë©´ cpu)",
    )
    return ap.parse_args()


# def load_model(device: str):
#     print(f"ðŸ” Loading ViT violence model: {MODEL_ID} ...")
#     processor = AutoImageProcessor.from_pretrained(MODEL_ID)
#     model = ViTForImageClassification.from_pretrained(MODEL_ID)
#     model.to(device)
#     model.eval()
#     return processor, model

@torch.no_grad()
def compute_violence_scores(
    processor,
    model,
    image_paths,
    device: str,
    batch_size: int = 16,
):
    """
    image_paths: ë¦¬ìŠ¤íŠ¸[str]
    ë°˜í™˜: dict {filename: {"violence_prob": float}}

    - jaranohaal/vit-base-violence-detection ì— ëŒ€í•´
      class 1 (index=1) ì˜ í™•ë¥ ì„ violence_prob ë¡œ ì‚¬ìš©
    """
    v_idx = 1  # âœ… Violent í´ëž˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ 1ë¡œ ê³ ì •

    per_frame = {}

    for i in tqdm(range(0, len(image_paths), batch_size), desc="ViT Violence"):
        chunk = image_paths[i: i + batch_size]
        images = []
        valid_paths = []
        for p in chunk:
            try:
                img = Image.open(p).convert("RGB")
                images.append(img)
                valid_paths.append(p)
            except Exception:
                continue

        if not images:
            continue

        inputs = processor(images=images, return_tensors="pt").to(device)
        outputs = model(**inputs)
        logits = outputs.logits  # [B, num_labels]
        probs = torch.softmax(logits, dim=-1)  # softmax

        for path, prob_vec in zip(valid_paths, probs):
            prob_vec = prob_vec.cpu().numpy()
            v_prob = float(prob_vec[v_idx])
            v_prob = float(np.clip(v_prob, 0.0, 1.0))
            fname = os.path.basename(path)
            per_frame[fname] = {"violence_prob": v_prob}

    return per_frame



if __name__ == "__main__":
    args = parse_args()

    device = args.device
    if device is None:
        device = "cuda:0" if torch.cuda.is_available() else "cpu"

    frames_dir = args.frames
    out_path = args.out

    imgs = sorted(
        [
            p
            for p in glob(os.path.join(frames_dir, "*"))
            if p.lower().endswith((".jpg", ".jpeg", ".png"))
        ]
    )

    num_total = len(imgs)
    if num_total == 0:
        print("âš ï¸ No frames found for ViT violence.")
        result = {
            "model": MODEL_ID,
            "frames_dir": frames_dir,
            "num_frames_total": 0,
            "num_frames_used": 0,
            "per_frame": {},
            "overall": {
                "avg_violence_prob": 0.0,
                "max_violence_prob": 0.0,
                "p95_violence_prob": 0.0,
            },
        }
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        json.dump(result, open(out_path, "w"), indent=2, ensure_ascii=False)
        print(f"âœ… ViT violence saved -> {out_path}")
        raise SystemExit(0)

    # stride ì ìš©í•´ì„œ ì¼ë¶€ í”„ë ˆìž„ë§Œ ì‚¬ìš©
    imgs_used = imgs[:: max(1, args.stride)]
    num_used = len(imgs_used)
    print(f"ðŸ–¼  ViT Violence: {num_total} frames ì¤‘ {num_used}ê°œ ì‚¬ìš© (stride={args.stride})")

    processor, model = load_model(device)
    per_frame = compute_violence_scores(
        processor,
        model,
        imgs_used,
        device=device,
        batch_size=args.batch,
    )

    if per_frame:
        vals = [v["violence_prob"] for v in per_frame.values()]
        avg_v = float(np.mean(vals))
        max_v = float(np.max(vals))
        p95_v = float(np.percentile(vals, 95))
    else:
        avg_v = max_v = p95_v = 0.0

    result = {
        "model": MODEL_ID,
        "frames_dir": frames_dir,
        "num_frames_total": num_total,
        "num_frames_used": num_used,
        "per_frame": per_frame,
        "overall": {
            "avg_violence_prob": avg_v,
            "max_violence_prob": max_v,
            "p95_violence_prob": p95_v,
        },
    }

    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    print(
        f"âœ… ViT violence saved -> {out_path} | "
        f"avg={avg_v:.3f}, max={max_v:.3f}, p95={p95_v:.3f}"
    )
