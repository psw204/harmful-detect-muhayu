#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import json
import subprocess

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# =========================================
# íŒ€ì› ë°ì´í„° ê²½ë¡œ
# =========================================
TEAM_ROOT       = os.path.join(BASE_DIR, "íŒ€ì›_ë¼ë²¨ë§", "íŒ€ì›_ë°ì´í„°")
HARM_VIDEO_DIR  = os.path.join(TEAM_ROOT, "ë¹„ë””ì˜¤")
SAFE_VIDEO_DIR  = os.path.join(TEAM_ROOT, "ì•ˆì „_ë¹„ë””ì˜¤")
LABEL_DIR       = os.path.join(TEAM_ROOT, "ë¼ë²¨_ê²°ê³¼")
FRAMES_ROOT     = os.path.join(TEAM_ROOT, "video_frames")

os.makedirs(LABEL_DIR, exist_ok=True)
os.makedirs(FRAMES_ROOT, exist_ok=True)

# =========================================
# ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ
# =========================================
SCRIPT_DIR      = os.path.join(BASE_DIR, "scripts")

VIDEO_SPLIT_PY  = os.path.join(SCRIPT_DIR, "video_split.py")
CLIP_PY         = os.path.join(SCRIPT_DIR, "vision_clip_violence.py")
VIT_PY          = os.path.join(SCRIPT_DIR, "vision_vit.py")
AUDIO_YAMNET_PY = os.path.join(SCRIPT_DIR, "audio_yamnet.py")
SLOWFAST_PY     = os.path.join(SCRIPT_DIR, "video_slowfast.py")
TEXT_OCR_PY     = os.path.join(SCRIPT_DIR, "text_ocr_kohate.py")
FUSION_PY       = os.path.join(SCRIPT_DIR, "fusion_scores.py")  # YOLO ì—†ëŠ” ë²„ì „

PY_TORCH = "../../Capstone2/Im/venv_pt/bin/python"
PY_TF    = "../../Capstone2/Im/venv_tf/bin/python"

def run(cmd, env=None):
    print("â–¶", " ".join(str(x) for x in cmd))
    p = subprocess.run(cmd, env=env)
    if p.returncode != 0:
        raise RuntimeError("Command failed: " + " ".join(str(x) for x in cmd))

def load_json(path, default=None):
    if default is None:
        default = {}
    if not os.path.exists(path):
        return default
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return default

def round5(x):
    return round(float(x), 5)

# =========================================
# 1) ìë™ ë¼ë²¨ ìƒì„±
# =========================================
def auto_generate_video_labels():
    harm_files = sorted([f for f in os.listdir(HARM_VIDEO_DIR)
        if f.lower().endswith((".mp4", ".avi", ".mov", ".mkv"))])
    safe_files = sorted([f for f in os.listdir(SAFE_VIDEO_DIR)
        if f.lower().endswith((".mp4", ".avi", ".mov", ".mkv"))])

    verified_video_labels = {f: 1 for f in harm_files}
    safe_video_labels = {f: 0 for f in safe_files}

    json.dump(verified_video_labels,
              open(os.path.join(LABEL_DIR, "verified_video_labels.json"), "w", encoding="utf-8"),
              indent=2, ensure_ascii=False)

    json.dump(safe_video_labels,
              open(os.path.join(LABEL_DIR, "safe_video_labels.json"), "w", encoding="utf-8"),
              indent=2, ensure_ascii=False)

    print(f"ğŸ”¹ ë¹„ë””ì˜¤ ìë™ ë¼ë²¨ ìƒì„±: harmful={len(verified_video_labels)}, safe={len(safe_video_labels)}")

    return verified_video_labels, safe_video_labels


# =========================================
# 2) í•œ ì˜ìƒ ì „ì²´ ì²˜ë¦¬
# =========================================
def process_one_video(video_path):
    video_name = os.path.basename(video_path)
    stem, _ = os.path.splitext(video_name)

    frames_dir = os.path.join(FRAMES_ROOT, stem)
    os.makedirs(frames_dir, exist_ok=True)

    FRAMES_JSON   = os.path.join(frames_dir, "meta.json")
    CLIP_JSON     = os.path.join(frames_dir, "clip_result.json")
    VIT_JSON      = os.path.join(frames_dir, "vit_result.json")
    AUDIO_WAV     = os.path.join(frames_dir, f"{stem}_audio.wav")
    AUDIO_JSON    = os.path.join(frames_dir, "audio_result.json")
    TEXT_JSON     = os.path.join(frames_dir, "text_result.json")
    SLOWFAST_JSON = os.path.join(frames_dir, "slowfast_result.json")
    FUSED_JSON    = os.path.join(frames_dir, "fusion_result.json")

    # 1) ì˜ìƒ ë¶„í• 
    run([
        PY_TORCH, VIDEO_SPLIT_PY,
        "--video", video_path,
        "--out", frames_dir,
        "--clip-sec", "2"
    ])

    meta = load_json(FRAMES_JSON, {})
    meta_meta = meta.get("meta", {}) if isinstance(meta.get("meta", {}), dict) else meta
    fps = meta_meta.get("fps", 30.0)
    total_frames = meta_meta.get("total_frames_saved") or meta_meta.get("frames") or 0
    try:
        fps = float(fps)
    except:
        fps = 30.0
    try:
        total_frames = int(total_frames)
    except:
        total_frames = 0

    duration = float(total_frames) / fps if fps > 0 and total_frames > 0 else 0.0

    print(f"[{video_name}] fps = {fps}")

    # 2) CLIP
    run([
        PY_TORCH, CLIP_PY,
        "--frames", frames_dir,
        "--out", CLIP_JSON,
        "--batch", "16",
        "--stride", "10"
    ])

    # 3) ViT
    run([
        PY_TORCH, VIT_PY,
        "--frames", frames_dir,
        "--out", VIT_JSON,
        "--batch", "16",
        "--stride", "10"
    ])

    # 4) Audio + YAMNet  (ë¬´ìŒ ì˜ìƒ ëŒ€ì‘)
    audio_ok = False

    if not os.path.exists(AUDIO_WAV):
        cmd = [
            "ffmpeg", "-hide_banner", "-nostdin",
            "-i", video_path, "-ac", "1", "-ar", "16000", "-vn",
            AUDIO_WAV, "-y"
        ]
        print("â–¶", " ".join(cmd))
        p = subprocess.run(cmd)
        if p.returncode == 0 and os.path.exists(AUDIO_WAV):
            audio_ok = True
        else:
            print(f"âš ï¸ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì´ ì—†ì–´ì„œ YAMNet ìŠ¤í‚µ: {video_path}")
    else:
        audio_ok = True

    if audio_ok:
        # ì‹¤ì œ YAMNet ì‹¤í–‰
        tf_env = os.environ.copy()
        tf_env["CUDA_VISIBLE_DEVICES"] = "-1"
        tf_env["TF_ENABLE_ONEDNN_OPTS"] = "0"
        tf_env["TF_CPP_MIN_LOG_LEVEL"] = "2"

        run([
            PY_TF, AUDIO_YAMNET_PY,
            "--audio", AUDIO_WAV,
            "--out", AUDIO_JSON
        ], env=tf_env)
    else:
        # ë”ë¯¸ audio_result.json ìƒì„± (fusionìš©)
        dummy_audio = {
            "overall": {
                "violent_audio_prob": 0.0,
                "has_audio": False
            }
        }
        with open(AUDIO_JSON, "w", encoding="utf-8") as f:
            json.dump(dummy_audio, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ dummy audio_result.json ìƒì„± -> {AUDIO_JSON}")

    # 5) TEXT (OCR + KoBERT) â€” í…ìŠ¤íŠ¸ ì—†ìœ¼ë©´ dummy
    # frames_dir ì•ˆì—ì„œ ì•„ë¬´ JPG/PNG í•˜ë‚˜ ê³¨ë¼ì„œ OCRì— ì‚¬ìš©
    frame_imgs = [
        f for f in os.listdir(frames_dir)
        if f.lower().endswith((".jpg", ".jpeg", ".png"))
    ]
    frame_imgs.sort()

    text_ok = False
    ocr_output_txt = os.path.join(frames_dir, "ocr_text.txt")

    if frame_imgs:
        first_frame = os.path.join(frames_dir, frame_imgs[0])

        try:
            # text_ocr_kohate.pyê°€ "ì´ë¯¸ì§€ 1ì¥ â†’ text_result.json" ê¹Œì§€ í•œ ë°©ì— í•˜ëŠ” êµ¬ì¡°ë¼ë©´:
            #   --image: ì…ë ¥ ì´ë¯¸ì§€
            #   --out:   text_result.json (overall.hate_prob, overall.sexual_text_prob ë“±)
            run([
                PY_TORCH,
                TEXT_OCR_PY,
                "--image", first_frame,
                "--out", TEXT_JSON
            ])
            if os.path.exists(TEXT_JSON):
                text_ok = True
        except RuntimeError:
            print(f"âš ï¸ í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨, dummyë¡œ ëŒ€ì²´: {video_path}")
            text_ok = False
    else:
        print(f"âš ï¸ í”„ë ˆì„ ì´ë¯¸ì§€ê°€ ì—†ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ ìŠ¤í‚µ: {video_path}")

    if not text_ok:
        dummy_text = {
            "overall": {
                "hate_prob": 0.0,
                "sexual_text_prob": 0.0,
                "has_text": False
            }
        }
        with open(TEXT_JSON, "w", encoding="utf-8") as f:
            json.dump(dummy_text, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ dummy text_result.json ìƒì„± -> {TEXT_JSON}")

     # 6) SlowFast
    run([
        PY_TORCH, SLOWFAST_PY,
        "--frames", frames_dir,
        "--out", SLOWFAST_JSON,
        "--frames-per-clip", "32",
        "--fps", str(fps)
    ])

    # 7) Fusion (YOLO ì—†ìŒ)
    run([
        PY_TORCH, FUSION_PY,
        "--clip", CLIP_JSON,
        "--vit", VIT_JSON,
        "--audio", AUDIO_JSON,
        "--text", TEXT_JSON,
        "--slowfast", SLOWFAST_JSON,
        "--out", FUSED_JSON
    ])

    fused = load_json(FUSED_JSON, {})
    violence_prob = fused.get("overall", {}).get("violence_prob", 0.0)

    # ---- CLIP ì‚¬ìš© í”„ë ˆì„ ìˆ˜ ì¶”ì¶œ (ê°€ëŠ¥í•œ ê²½ìš°) ----
    clip_meta = load_json(CLIP_JSON, {})
    sampled_frames = 0

    # 1) meta.sampled_frames ìš°ì„ 
    meta_clip = clip_meta.get("meta", {})
    if isinstance(meta_clip, dict) and "sampled_frames" in meta_clip:
        try:
            sampled_frames = int(meta_clip["sampled_frames"])
        except:
            sampled_frames = 0

    # 2) fallback: overall.sampled_frames
    if sampled_frames == 0:
        overall_clip = clip_meta.get("overall", {})
        if isinstance(overall_clip, dict) and "sampled_frames" in overall_clip:
            try:
                sampled_frames = int(overall_clip["sampled_frames"])
            except:
                sampled_frames = 0

    # 3) fallback: frames ë¦¬ìŠ¤íŠ¸ ê¸¸ì´
    if sampled_frames == 0 and "frames" in clip_meta and isinstance(clip_meta["frames"], list):
        sampled_frames = len(clip_meta["frames"])


    # ---- SlowFastì—ì„œ ëŒ€í‘œ í–‰ë™ ì¶”ì¶œ ----
    slow_json = load_json(SLOWFAST_JSON, {})
    estimated_action = None
    clips = slow_json.get("clips") or []
    if clips:
        # ê° í´ë¦½ì—ì„œ top-1 label ë½‘ì•„ì„œ ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ê±¸ ëŒ€í‘œë¡œ ì‚¬ìš©
        from collections import Counter
        labels = []
        for c in clips:
            topk = c.get("topk") or []
            if topk:
                labels.append(topk[0].get("label"))
        if labels:
            estimated_action = Counter(labels).most_common(1)[0][0]
    if not estimated_action:
        estimated_action = "unknown"

    # ---- YOLOë¥¼ ì•ˆ ì“°ê³  ìˆìœ¼ë¯€ë¡œ object ê´€ë ¨ í•„ë“œëŠ” ë¹ˆ ê°’ìœ¼ë¡œ ----
    detected_objects = []
    total_detections = 0
    frame_detections = []

    violence_prob = round5(violence_prob)
    print(f"[{video_name}] ğŸ”¥ violence_prob = {violence_prob}")

    video_stats = {
        "duration": duration,
        "fps": fps,
        "total_frames": total_frames,
        "sampled_frames": sampled_frames,
        "detected_objects": detected_objects,
        "total_detections": total_detections,
        "frame_detections": frame_detections,
        "estimated_action": estimated_action,
    }

    # ğŸ‘‰ ì´ì œ ì ìˆ˜ + ë©”íƒ€ ì •ë³´ ë‘˜ ë‹¤ ë°˜í™˜
    return violence_prob, video_stats



# =========================================
# 3) ìµœì¢… ë¼ë²¨ ê°±ì‹ 
# =========================================
def merge_scores_and_update_video_labels(verified, safe):
    TH = 0.45

    # -------------------------------
    # 1) ìœ í•´ ë¹„ë””ì˜¤ (GT=1)
    # -------------------------------
    for fname in verified.keys():
        video_path = os.path.join(HARM_VIDEO_DIR, fname)
        score, stats = process_one_video(video_path)
        pred = 1 if score >= TH else 0

        verified[fname] = {
            "duration": stats["duration"],
            "fps": stats["fps"],
            "total_frames": stats["total_frames"],
            "sampled_frames": stats["sampled_frames"],
            "detected_objects": stats.get("detected_objects", []),
            "total_detections": stats.get("total_detections", 0),
            "frame_detections": stats.get("frame_detections", []),
            "estimated_action": stats["estimated_action"],
            "is_harmful": True,   # GT ë¼ë²¨
            "label": 1,
            "pred_label": pred,
            "violence_prob": score,
        }

    # -------------------------------
    # 2) ì•ˆì „ ë¹„ë””ì˜¤ (GT=0)
    # -------------------------------
    for fname in safe.keys():
        video_path = os.path.join(SAFE_VIDEO_DIR, fname)
        score, stats = process_one_video(video_path)
        pred = 1 if score >= TH else 0

        # ëª¨ë¸ì´ 1ë¡œ ì°ìœ¼ë©´ "ì•ˆì „ì¸ë° ìœ í•´ë¡œ ë³¸ ì¼€ì´ìŠ¤" â†’ review
        category = "safe" if pred == 0 else "review"

        safe[fname] = {
            "is_safe": True,   # GT ê¸°ì¤€
            "label": 0,
            "pred_label": pred,
            "category": category,
            "duration": stats["duration"],
            "fps": stats["fps"],
            "total_frames": stats["total_frames"],
            "sampled_frames": stats["sampled_frames"],
            "estimated_action": stats["estimated_action"],
            "violence_prob": score,
        }

    # ì €ì¥ ê·¸ëŒ€ë¡œ
    json.dump(verified,
              open(os.path.join(LABEL_DIR, "verified_video_labels.json"), "w", encoding="utf-8"),
              indent=2, ensure_ascii=False)

    json.dump(safe,
              open(os.path.join(LABEL_DIR, "safe_video_labels.json"), "w", encoding="utf-8"),
              indent=2, ensure_ascii=False)

    print("âœ… ë¹„ë””ì˜¤ ë¼ë²¨ ì €ì¥ ì™„ë£Œ ")

# =========================================
# ìƒˆë¡œ ë¼ë²¨ íŒŒì¼ë§Œ ë§Œë“œëŠ” ì¬ë¹Œë“œ ëª¨ë“œ
# =========================================
def rebuild_labels_only():
    verified = {}
    safe = {}

    # ê¸°ë³¸ TH (í•„ìš”í•˜ë©´ ì¡°ì • ê°€ëŠ¥)
    TH = 0.45

    # ---------------------------
    # 1) ìœ í•´ ë¹„ë””ì˜¤(GT=1)
    # ---------------------------
    for fname in sorted(os.listdir(HARM_VIDEO_DIR)):
        if not fname.lower().endswith((".mp4", ".avi", ".mov", ".mkv")):
            continue

        stem, _ = os.path.splitext(fname)
        frames_dir = os.path.join(FRAMES_ROOT, stem)

        fusion_path = os.path.join(frames_dir, "fusion_result.json")
        clip_path   = os.path.join(frames_dir, "clip_result.json")
        slow_path   = os.path.join(frames_dir, "slowfast_result.json")
        meta_path   = os.path.join(frames_dir, "meta.json")

        fusion = load_json(fusion_path, {})
        clip   = load_json(clip_path, {})
        slow   = load_json(slow_path, {})
        meta   = load_json(meta_path, {})

        # violence_prob
        violence = float(
            fusion.get("overall", {}).get(
                "violence_prob",
                fusion.get("scores", {}).get("final", 0.0)
            )
        )

        # metaì—ì„œ fps, total_frames, duration
        m = meta.get("meta", {}) if isinstance(meta.get("meta", {}), dict) else meta
        fps = float(m.get("fps", 30.0))
        total_frames = int(m.get("total_frames_saved") or m.get("frames") or 0)
        duration = total_frames / fps if fps > 0 else 0.0

        # sampled_frames ì¶”ì¶œ
        sampled_frames = 0
        mc = clip.get("meta", {})
        if "sampled_frames" in mc:
            sampled_frames = mc["sampled_frames"]
        elif "frames" in clip:
            sampled_frames = len(clip["frames"])

        # estimated_action (slowfast)
        est = "unknown"
        clips = slow.get("clips") or []
        if clips:
            from collections import Counter
            labels = []
            for c in clips:
                topk = c.get("topk") or []
                if topk:
                    lab = topk[0].get("label", "")
                    lab = str(lab).split("\t")[0]  # ë²ˆí˜¸ ì œê±°
                    labels.append(lab)
            if labels:
                est = Counter(labels).most_common(1)[0][0]

        pred = 1 if violence >= TH else 0

        verified[fname] = {
            "duration": duration,
            "fps": fps,
            "total_frames": total_frames,
            "sampled_frames": sampled_frames,
            "detected_objects": [],
            "total_detections": 0,
            "frame_detections": [],
            "estimated_action": est,
            "is_harmful": True,
            "label": 1,
            "pred_label": pred,
            "violence_prob": violence
        }

    # ---------------------------
    # 2) ì•ˆì „ ë¹„ë””ì˜¤(GT=0)
    # ---------------------------
    for fname in sorted(os.listdir(SAFE_VIDEO_DIR)):
        if not fname.lower().endswith((".mp4", ".avi", ".mov", ".mkv")):
            continue

        stem, _ = os.path.splitext(fname)
        frames_dir = os.path.join(FRAMES_ROOT, stem)

        fusion_path = os.path.join(frames_dir, "fusion_result.json")
        clip_path   = os.path.join(frames_dir, "clip_result.json")
        slow_path   = os.path.join(frames_dir, "slowfast_result.json")
        meta_path   = os.path.join(frames_dir, "meta.json")

        fusion = load_json(fusion_path, {})
        clip   = load_json(clip_path, {})
        slow   = load_json(slow_path, {})
        meta   = load_json(meta_path, {})

        violence = float(
            fusion.get("overall", {}).get(
                "violence_prob",
                fusion.get("scores", {}).get("final", 0.0)
            )
        )

        m = meta.get("meta", {}) if isinstance(meta.get("meta", {}), dict) else meta
        fps = float(m.get("fps", 30.0))
        total_frames = int(m.get("total_frames_saved") or m.get("frames") or 0)
        duration = total_frames / fps if fps > 0 else 0.0

        sampled_frames = 0
        mc = clip.get("meta", {})
        if "sampled_frames" in mc:
            sampled_frames = mc["sampled_frames"]
        elif "frames" in clip:
            sampled_frames = len(clip["frames"])

        est = "unknown"
        clips = slow.get("clips") or []
        if clips:
            from collections import Counter
            labels = []
            for c in clips:
                topk = c.get("topk") or []
                if topk:
                    lab = topk[0].get("label", "")
                    lab = str(lab).split("\t")[0]
                    labels.append(lab)
            if labels:
                est = Counter(labels).most_common(1)[0][0]

        pred = 1 if violence >= TH else 0
        category = "safe" if pred == 0 else "review"

        safe[fname] = {
            "is_safe": True,
            "label": 0,
            "pred_label": pred,
            "category": category,
            "duration": duration,
            "fps": fps,
            "total_frames": total_frames,
            "sampled_frames": sampled_frames,
            "estimated_action": est,
            "violence_prob": violence
        }

    # ì €ì¥
    json.dump(verified,
              open(os.path.join(LABEL_DIR, "verified_video_labels.json"), "w", encoding="utf-8"),
              indent=2, ensure_ascii=False)

    json.dump(safe,
              open(os.path.join(LABEL_DIR, "safe_video_labels.json"), "w", encoding="utf-8"),
              indent=2, ensure_ascii=False)

    print("ğŸ¯ ê¸°ì¡´ ê²°ê³¼ ê¸°ë°˜ ë¼ë²¨ íŒŒì¼ ì¬ìƒì„± ì™„ë£Œ!")

# =========================================
# MAIN
# =========================================
def main():
    rebuild_labels_only()
    # verified, safe = auto_generate_video_labels()
    # merge_scores_and_update_video_labels(verified, safe)
    # print("\nğŸ‰ ì „ì²´ ë¹„ë””ì˜¤ ë©€í‹°ëª¨ë‹¬ ë¼ë²¨ë§ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
