Multimodal Harmful Content Detection (Prototype)

ë¹„ë””ì˜¤/ì´ë¯¸ì§€ ê¸°ë°˜ ìœ í•´ ì½˜í…ì¸ (í­ë ¥/ë¬´ê¸°/í˜ì˜¤ ë“±)ë¥¼ ëª¨ë‹¬ë³„ ëª¨ë¸ë¡œ ë¶„ì„í•˜ê³ , ê²°ê³¼ë¥¼ Fusion Scoreë¡œ í•©ì‚°í•´ ê²°ì •ì„ ë‚´ë¦¬ëŠ” í”„ë¡œí† íƒ€ì… íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

êµ¬ì„± ìš”ì†Œ:
ğŸï¸ Video â†’ Frames ë¶„í• 
ğŸ§  Vision(í­ë ¥): CLIP / ViT
ğŸƒ Action(í­ë ¥ í–‰ë™): SlowFast R101
ğŸ”Š Audio(ë¹„ëª…/ì´ì„± ë“±): YAMNet
ğŸ§¾ Text(ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸): PaddleOCR + Toxicity Classifier
ğŸ§® Fusion Scoring: ëª¨ë‹¬ ì ìˆ˜ ê²°í•© ë° ì„ê³„ì¹˜ ê¸°ë°˜ íŒì •

íŒŒì¼ êµ¬ì¡°:
scripts/
    video_split.py          # ë¹„ë””ì˜¤ í´ë¦½/í”„ë ˆì„ ë¶„í• 
    vision_clip_violence.py 
    vision_vit.py           
    video_slowfast.py
    audio_yamnet.py
    text_toxic.py
    fusion_scores.py
    kinetics_400_labels.txt
    vit_finetuned.pth 
íŒ€ì›_ë¼ë²¨ë§_ëª¨ë¸ì„ ì •/
    ê²°ê³¼_ë°ì´í„°_32/ # 32í”„ë ˆì„ ê· ë“±ë¶„í•  - ìµœì¢… ë°ì´í„°
        {ì‚¬ëŒ ì´ë¦„}/
            ë¼ë²¨ê²°ê³¼/ # label = 0 if category == "safe" else 1, pred_label == final_label
                safe_labels.json  
                safe_video_labels.json
                verified_labels.json
                verified_video_labels.json
            video_frames/
                ë¹„ë””ì˜¤/
                    {ë¹„ë””ì˜¤ ì´ë¦„}/
                        ë¹„ë””ì˜¤í”„ë ˆì„ ëª¨ìŒ/
                            **.jpg
                            ...
                        audio_result.json
                        clip_result.json
                        fusion_result.json # ëª¨ë“  ëª¨ë¸ì˜ ì ìˆ˜ ë° ê°€ì¤‘ì¹˜ ë‚´í¬
                        slowfast_result.json
                        text_result.json
                        vit_result.json
                ì•ˆì „ë¹„ë””ì˜¤/
                    ìœ„ì™€ ë™
    ê²°ê³¼_ë°ì´í„°_training/ # í•™ìŠµ ë°ì´í„° ê²°ê³¼ë¬¼ 32í”„ë ˆì„ ê· ë“±ë¶„í• 
    evaluate_training.py            # í•™ìŠµ ë°ì´í„° ë¶„ì„
    final_model_img_training.py
    final_model_video_training.py
    evaluate.py                     # ìµœì¢… ê²°ê³¼ ë¶„ì„
    final_model_img.py              # ì´ë¯¸ì§€ ëª¨ë¸ clip + vit
    final_model_video.py            # ë¹„ë””ì˜¤ ëª¨ë¸ clip + vit + slowfast + ( audio + text )


ë°ì´í„° ê²€ì‚¬ë„êµ¬

A. ë¹„ë””ì˜¤ ê²€ì‚¬ë„êµ¬ final_model_video.py

    í”„ë ˆì„/í´ë¦½
        video_split.py --clip-sec 2 (2ì´ˆ ë‹¨ìœ„ë¡œ í”„ë ˆì„ ì €ì¥ - ì˜ë¯¸ x)
        CLIP/VIT/SlowFast ëª¨ë‘ ê· ë“± 32í”„ë ˆì„ ìƒ˜í”Œë§: TARGET = 32
        SlowFast ì…ë ¥ ê¸¸ì´: frames_per_clip = 32
        SlowFast ì…ë ¥ ë¦¬ì‚¬ì´ì¦ˆ: Resize((224,224))
        SlowFast í´ë˜ìŠ¤: Kinetics-400 (num_classes=400)

    ëª¨ë¸ ì‹¤í–‰ íŒŒë¼ë¯¸í„°
        CLIP
            batch_size = 16
            temperature = 2.0
            (í•¨ìˆ˜ ì¸ìë¡œ stride=10ì´ ìˆì§€ë§Œ, í˜„ì¬ ì½”ë“œì—ì„œëŠ” ìƒ˜í”Œë§ì„ ê· ë“± 32ë¡œ í•´ë²„ë ¤ì„œ strideëŠ” ì‚¬ì‹¤ìƒ ì˜ë¯¸ ì—†ìŒ)
        ViT
            batch_size = 16
        SlowFast
            topk = 5 (top5 ë½‘ìŒ)
        ì˜¤ë””ì˜¤/í…ìŠ¤íŠ¸
            ì˜¤ë””ì˜¤ ì¶”ì¶œ: ffmpeg -ac 1 -ar 16000
            YAMNet ì‹¤í–‰ í™˜ê²½
                CUDA_VISIBLE_DEVICES = -1 (TFëŠ” CPU ê°•ì œ)
                TF_ENABLE_ONEDNN_OPTS=0, TF_CPP_MIN_LOG_LEVEL=2
            í…ìŠ¤íŠ¸(OCR+toxic)

    ìµœì¢… íŒì •
        ê°€ì¤‘ì¹˜/ì„ê³„ê°’
            W_CLIP = 0.8
            W_VIT = 0.1
            W_SLOWFAST = 0.1
            W_AUDIO = 0 (ë°ì´í„°ì…‹ ë‚´ ì˜ìƒì— ì†Œë¦¬ì™€ ìë§‰ì´ ì—†ëŠ” íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ íŒë³„ ê¸°ì¤€ì—ì„œ ì œì™¸)
            W_TEXT = 0
            threshold = 0.63
            fused = 0.8*clip + 0.1*vit + 0.1*slowfast
            pred_label = 1 if fused >= 0.63 else 0
            ê¸°ì¡´ ë¼ë²¨(label)
                *_labels_categorized.jsonì—ì„œ label = 0 if category == "safe" else 1

B. ì´ë¯¸ì§€ ê²€ì‚¬ë„êµ¬ final_model_img.py

    ê°€ì¤‘ì¹˜/ì„ê³„ê°’
        W_CLIP = 0.8
        W_VIT = 0.2
        threshold = 0.35
        fused = 0.8*clip + 0.2*vit
        pred_label = 1 if fused >= 0.35 else 0

    ëª¨ë¸ ì‹¤í–‰
        CLIP: --batch 16 --stride 1
        ViT : --batch 16 --stride 1
